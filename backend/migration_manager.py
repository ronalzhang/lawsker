#!/usr/bin/env python3
"""
Lawskeræ•°æ®åº“è¿ç§»ç®¡ç†å™¨
ç¡®ä¿100%æˆåŠŸç‡ï¼Œé›¶æ•°æ®ä¸¢å¤±çš„æ•°æ®åº“è¿ç§»ç³»ç»Ÿ
"""

import asyncio
import asyncpg
import os
import json
import logging
import subprocess
import shutil
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('migration.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class MigrationResult:
    """è¿ç§»ç»“æœæ•°æ®ç±»"""
    success: bool
    migration_id: str
    start_time: datetime
    end_time: Optional[datetime] = None
    backup_path: Optional[str] = None
    error_message: Optional[str] = None
    tables_created: List[str] = None
    records_migrated: Dict[str, int] = None
    rollback_performed: bool = False

class DatabaseBackupManager:
    """æ•°æ®åº“å¤‡ä»½ç®¡ç†å™¨"""
    
    def __init__(self, database_url: str):
        self.database_url = database_url
        self.backup_dir = Path("backups")
        self.backup_dir.mkdir(exist_ok=True)
    
    async def create_backup(self, backup_name: str) -> str:
        """åˆ›å»ºæ•°æ®åº“å¤‡ä»½"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"{backup_name}_{timestamp}.sql"
        backup_path = self.backup_dir / backup_filename
        
        logger.info(f"ğŸ”„ å¼€å§‹åˆ›å»ºæ•°æ®åº“å¤‡ä»½: {backup_path}")
        
        try:
            # è§£ææ•°æ®åº“URL
            db_params = self._parse_database_url(self.database_url)
            
            # ä½¿ç”¨pg_dumpåˆ›å»ºå¤‡ä»½
            cmd = [
                "pg_dump",
                "-h", db_params["host"],
                "-p", str(db_params["port"]),
                "-U", db_params["user"],
                "-d", db_params["database"],
                "-f", str(backup_path),
                "--verbose",
                "--no-password"
            ]
            
            env = os.environ.copy()
            env["PGPASSWORD"] = db_params["password"]
            
            result = subprocess.run(cmd, env=env, capture_output=True, text=True)
            
            if result.returncode != 0:
                raise Exception(f"pg_dump failed: {result.stderr}")
            
            # éªŒè¯å¤‡ä»½æ–‡ä»¶
            if not backup_path.exists() or backup_path.stat().st_size == 0:
                raise Exception("å¤‡ä»½æ–‡ä»¶åˆ›å»ºå¤±è´¥æˆ–ä¸ºç©º")
            
            logger.info(f"âœ… æ•°æ®åº“å¤‡ä»½åˆ›å»ºæˆåŠŸ: {backup_path}")
            return str(backup_path)
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“å¤‡ä»½åˆ›å»ºå¤±è´¥: {e}")
            raise
    
    def _parse_database_url(self, url: str) -> Dict[str, str]:
        """è§£ææ•°æ®åº“URL"""
        # postgresql://user:password@host:port/database
        import urllib.parse
        parsed = urllib.parse.urlparse(url)
        
        return {
            "host": parsed.hostname or "localhost",
            "port": parsed.port or 5432,
            "user": parsed.username or "postgres",
            "password": parsed.password or "",
            "database": parsed.path.lstrip("/") or "postgres"
        }
    
    async def restore_backup(self, backup_path: str) -> bool:
        """ä»å¤‡ä»½æ¢å¤æ•°æ®åº“"""
        logger.info(f"ğŸ”„ å¼€å§‹ä»å¤‡ä»½æ¢å¤æ•°æ®åº“: {backup_path}")
        
        try:
            db_params = self._parse_database_url(self.database_url)
            
            # ä½¿ç”¨psqlæ¢å¤å¤‡ä»½
            cmd = [
                "psql",
                "-h", db_params["host"],
                "-p", str(db_params["port"]),
                "-U", db_params["user"],
                "-d", db_params["database"],
                "-f", backup_path,
                "--quiet"
            ]
            
            env = os.environ.copy()
            env["PGPASSWORD"] = db_params["password"]
            
            result = subprocess.run(cmd, env=env, capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.error(f"âŒ æ•°æ®åº“æ¢å¤å¤±è´¥: {result.stderr}")
                return False
            
            logger.info("âœ… æ•°æ®åº“æ¢å¤æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“æ¢å¤å¤±è´¥: {e}")
            return False

class DataIntegrityValidator:
    """æ•°æ®å®Œæ•´æ€§éªŒè¯å™¨"""
    
    def __init__(self, connection: asyncpg.Connection):
        self.conn = connection
    
    async def validate_pre_migration(self) -> Dict[str, int]:
        """è¿ç§»å‰æ•°æ®éªŒè¯"""
        logger.info("ğŸ” å¼€å§‹è¿ç§»å‰æ•°æ®éªŒè¯")
        
        validation_results = {}
        
        try:
            # æ£€æŸ¥ç°æœ‰è¡¨çš„è®°å½•æ•°
            tables_to_check = [
                "users", "cases", "profiles", "user_roles", "roles"
            ]
            
            for table in tables_to_check:
                try:
                    count = await self.conn.fetchval(f"SELECT COUNT(*) FROM {table}")
                    validation_results[table] = count
                    logger.info(f"ğŸ“Š è¡¨ {table}: {count} æ¡è®°å½•")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ— æ³•æ£€æŸ¥è¡¨ {table}: {e}")
                    validation_results[table] = 0
            
            # æ£€æŸ¥æ•°æ®åº“è¿æ¥
            await self.conn.fetchval("SELECT 1")
            validation_results["connection_test"] = 1
            
            logger.info("âœ… è¿ç§»å‰æ•°æ®éªŒè¯å®Œæˆ")
            return validation_results
            
        except Exception as e:
            logger.error(f"âŒ è¿ç§»å‰æ•°æ®éªŒè¯å¤±è´¥: {e}")
            raise
    
    async def validate_post_migration(self, pre_migration_counts: Dict[str, int]) -> bool:
        """è¿ç§»åæ•°æ®éªŒè¯"""
        logger.info("ğŸ” å¼€å§‹è¿ç§»åæ•°æ®éªŒè¯")
        
        try:
            # éªŒè¯åŸæœ‰è¡¨çš„æ•°æ®å®Œæ•´æ€§
            for table, expected_count in pre_migration_counts.items():
                if table == "connection_test":
                    continue
                
                try:
                    actual_count = await self.conn.fetchval(f"SELECT COUNT(*) FROM {table}")
                    if actual_count != expected_count:
                        logger.error(f"âŒ è¡¨ {table} æ•°æ®ä¸¢å¤±: æœŸæœ› {expected_count}, å®é™… {actual_count}")
                        return False
                    logger.info(f"âœ… è¡¨ {table} æ•°æ®å®Œæ•´: {actual_count} æ¡è®°å½•")
                except Exception as e:
                    logger.error(f"âŒ æ— æ³•éªŒè¯è¡¨ {table}: {e}")
                    return False
            
            # éªŒè¯æ–°åˆ›å»ºçš„è¡¨
            new_tables = [
                "lawyer_certification_requests",
                "workspace_mappings", 
                "demo_accounts",
                "lawyer_levels",
                "lawyer_level_details",
                "user_credits",
                "lawyer_point_transactions",
                "collection_success_stats"
            ]
            
            for table in new_tables:
                try:
                    exists = await self.conn.fetchval(
                        "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = $1)",
                        table
                    )
                    if not exists:
                        logger.error(f"âŒ æ–°è¡¨ {table} æœªåˆ›å»º")
                        return False
                    logger.info(f"âœ… æ–°è¡¨ {table} åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    logger.error(f"âŒ æ— æ³•éªŒè¯æ–°è¡¨ {table}: {e}")
                    return False
            
            # éªŒè¯åˆå§‹æ•°æ®
            lawyer_levels_count = await self.conn.fetchval("SELECT COUNT(*) FROM lawyer_levels")
            if lawyer_levels_count != 10:
                logger.error(f"âŒ å¾‹å¸ˆç­‰çº§åˆå§‹æ•°æ®ä¸å®Œæ•´: æœŸæœ› 10, å®é™… {lawyer_levels_count}")
                return False
            
            logger.info("âœ… è¿ç§»åæ•°æ®éªŒè¯å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è¿ç§»åæ•°æ®éªŒè¯å¤±è´¥: {e}")
            return False

class MigrationManager:
    """æ•°æ®åº“è¿ç§»ç®¡ç†å™¨"""
    
    def __init__(self):
        self.database_url = os.getenv('DATABASE_URL', 'postgresql://postgres:postgres@localhost:5432/lawsker')
        self.backup_manager = DatabaseBackupManager(self.database_url)
        self.migration_log_file = "migration_results.json"
    
    async def execute_migration(self, migration_file: str) -> MigrationResult:
        """æ‰§è¡Œæ•°æ®åº“è¿ç§»"""
        migration_id = f"migration_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        start_time = datetime.now(timezone.utc)
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®åº“è¿ç§»: {migration_id}")
        
        result = MigrationResult(
            success=False,
            migration_id=migration_id,
            start_time=start_time,
            tables_created=[],
            records_migrated={}
        )
        
        conn = None
        transaction = None
        
        try:
            # 1. åˆ›å»ºæ•°æ®åº“å¤‡ä»½
            logger.info("ğŸ“¦ åˆ›å»ºæ•°æ®åº“å¤‡ä»½...")
            backup_path = await self.backup_manager.create_backup(f"pre_migration_{migration_id}")
            result.backup_path = backup_path
            
            # 2. å»ºç«‹æ•°æ®åº“è¿æ¥
            logger.info("ğŸ”— å»ºç«‹æ•°æ®åº“è¿æ¥...")
            conn = await asyncpg.connect(self.database_url)
            
            # 3. è¿ç§»å‰æ•°æ®éªŒè¯
            validator = DataIntegrityValidator(conn)
            pre_migration_counts = await validator.validate_pre_migration()
            
            # 4. å¼€å§‹äº‹åŠ¡
            logger.info("ğŸ”„ å¼€å§‹æ•°æ®åº“äº‹åŠ¡...")
            transaction = conn.transaction()
            await transaction.start()
            
            # 5. è¯»å–å¹¶æ‰§è¡Œè¿ç§»è„šæœ¬
            logger.info(f"ğŸ“œ è¯»å–è¿ç§»è„šæœ¬: {migration_file}")
            with open(migration_file, 'r', encoding='utf-8') as f:
                migration_sql = f.read()
            
            # åˆ†å‰²SQLè¯­å¥å¹¶é€ä¸ªæ‰§è¡Œ
            sql_statements = self._split_sql_statements(migration_sql)
            
            logger.info(f"ğŸ”§ æ‰§è¡Œ {len(sql_statements)} ä¸ªSQLè¯­å¥...")
            for i, statement in enumerate(sql_statements, 1):
                if statement.strip():
                    try:
                        await conn.execute(statement)
                        if i % 10 == 0:
                            logger.info(f"ğŸ“ˆ å·²æ‰§è¡Œ {i}/{len(sql_statements)} ä¸ªè¯­å¥")
                    except Exception as e:
                        logger.error(f"âŒ SQLè¯­å¥æ‰§è¡Œå¤±è´¥ (ç¬¬{i}ä¸ª): {e}")
                        logger.error(f"å¤±è´¥çš„è¯­å¥: {statement[:200]}...")
                        raise
            
            # 6. è¿ç§»åæ•°æ®éªŒè¯
            logger.info("ğŸ” æ‰§è¡Œè¿ç§»åæ•°æ®éªŒè¯...")
            validation_success = await validator.validate_post_migration(pre_migration_counts)
            
            if not validation_success:
                raise Exception("è¿ç§»åæ•°æ®éªŒè¯å¤±è´¥")
            
            # 7. æäº¤äº‹åŠ¡
            logger.info("âœ… æäº¤æ•°æ®åº“äº‹åŠ¡...")
            await transaction.commit()
            
            # 8. è®°å½•æˆåŠŸç»“æœ
            result.success = True
            result.end_time = datetime.now(timezone.utc)
            result.records_migrated = pre_migration_counts
            
            logger.info(f"ğŸ‰ æ•°æ®åº“è¿ç§»æˆåŠŸå®Œæˆ: {migration_id}")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿ç§»å¤±è´¥: {e}")
            result.error_message = str(e)
            result.end_time = datetime.now(timezone.utc)
            
            # å›æ»šäº‹åŠ¡
            if transaction:
                try:
                    logger.info("ğŸ”„ å›æ»šæ•°æ®åº“äº‹åŠ¡...")
                    await transaction.rollback()
                    result.rollback_performed = True
                    logger.info("âœ… äº‹åŠ¡å›æ»šæˆåŠŸ")
                except Exception as rollback_error:
                    logger.error(f"âŒ äº‹åŠ¡å›æ»šå¤±è´¥: {rollback_error}")
            
            # å¦‚æœéœ€è¦ï¼Œå¯ä»¥ä»å¤‡ä»½æ¢å¤
            # await self._emergency_restore(result.backup_path)
            
        finally:
            if conn:
                await conn.close()
        
        # ä¿å­˜è¿ç§»ç»“æœ
        await self._save_migration_result(result)
        
        return result
    
    def _split_sql_statements(self, sql_content: str) -> List[str]:
        """åˆ†å‰²SQLè¯­å¥"""
        # ç®€å•çš„SQLè¯­å¥åˆ†å‰²ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ”¹è¿›
        statements = []
        current_statement = ""
        in_function = False
        
        for line in sql_content.split('\n'):
            line = line.strip()
            
            # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
            if not line or line.startswith('--'):
                continue
            
            # æ£€æŸ¥æ˜¯å¦åœ¨å‡½æ•°å®šä¹‰ä¸­
            if 'CREATE OR REPLACE FUNCTION' in line.upper() or 'CREATE FUNCTION' in line.upper():
                in_function = True
            
            current_statement += line + '\n'
            
            # æ£€æŸ¥è¯­å¥ç»“æŸ
            if line.endswith(';'):
                if in_function and ('END;' in line.upper() or '$ LANGUAGE' in line.upper()):
                    in_function = False
                    statements.append(current_statement.strip())
                    current_statement = ""
                elif not in_function:
                    statements.append(current_statement.strip())
                    current_statement = ""
        
        # æ·»åŠ æœ€åä¸€ä¸ªè¯­å¥ï¼ˆå¦‚æœæœ‰ï¼‰
        if current_statement.strip():
            statements.append(current_statement.strip())
        
        return statements
    
    async def _save_migration_result(self, result: MigrationResult):
        """ä¿å­˜è¿ç§»ç»“æœ"""
        try:
            # è¯»å–ç°æœ‰ç»“æœ
            results = []
            if os.path.exists(self.migration_log_file):
                with open(self.migration_log_file, 'r', encoding='utf-8') as f:
                    results = json.load(f)
            
            # æ·»åŠ æ–°ç»“æœ
            result_dict = {
                "migration_id": result.migration_id,
                "success": result.success,
                "start_time": result.start_time.isoformat(),
                "end_time": result.end_time.isoformat() if result.end_time else None,
                "backup_path": result.backup_path,
                "error_message": result.error_message,
                "tables_created": result.tables_created or [],
                "records_migrated": result.records_migrated or {},
                "rollback_performed": result.rollback_performed
            }
            
            results.append(result_dict)
            
            # ä¿å­˜ç»“æœ
            with open(self.migration_log_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“ è¿ç§»ç»“æœå·²ä¿å­˜åˆ°: {self.migration_log_file}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è¿ç§»ç»“æœå¤±è´¥: {e}")
    
    async def verify_migration_success(self) -> bool:
        """éªŒè¯è¿ç§»æ˜¯å¦æˆåŠŸ"""
        logger.info("ğŸ” éªŒè¯è¿ç§»æˆåŠŸçŠ¶æ€...")
        
        try:
            conn = await asyncpg.connect(self.database_url)
            
            try:
                # æ£€æŸ¥å…³é”®è¡¨æ˜¯å¦å­˜åœ¨
                required_tables = [
                    "lawyer_certification_requests",
                    "workspace_mappings",
                    "demo_accounts", 
                    "lawyer_levels",
                    "lawyer_level_details",
                    "user_credits",
                    "lawyer_point_transactions"
                ]
                
                for table in required_tables:
                    exists = await conn.fetchval(
                        "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = $1)",
                        table
                    )
                    if not exists:
                        logger.error(f"âŒ å¿…éœ€è¡¨ {table} ä¸å­˜åœ¨")
                        return False
                
                # æ£€æŸ¥åˆå§‹æ•°æ®
                lawyer_levels_count = await conn.fetchval("SELECT COUNT(*) FROM lawyer_levels")
                if lawyer_levels_count != 10:
                    logger.error(f"âŒ å¾‹å¸ˆç­‰çº§æ•°æ®ä¸å®Œæ•´: {lawyer_levels_count}/10")
                    return False
                
                # æ£€æŸ¥ç”¨æˆ·è¡¨æ‰©å±•å­—æ®µ
                workspace_id_exists = await conn.fetchval(
                    "SELECT EXISTS (SELECT FROM information_schema.columns WHERE table_name = 'users' AND column_name = 'workspace_id')"
                )
                if not workspace_id_exists:
                    logger.error("âŒ ç”¨æˆ·è¡¨workspace_idå­—æ®µä¸å­˜åœ¨")
                    return False
                
                logger.info("âœ… è¿ç§»éªŒè¯æˆåŠŸ")
                return True
                
            finally:
                await conn.close()
                
        except Exception as e:
            logger.error(f"âŒ è¿ç§»éªŒè¯å¤±è´¥: {e}")
            return False

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Lawskeræ•°æ®åº“è¿ç§»ç®¡ç†å™¨")
    print("=" * 50)
    
    migration_manager = MigrationManager()
    migration_file = "backend/migrations/013_business_optimization_tables.sql"
    
    if not os.path.exists(migration_file):
        print(f"âŒ è¿ç§»æ–‡ä»¶ä¸å­˜åœ¨: {migration_file}")
        return
    
    # æ‰§è¡Œè¿ç§»
    result = await migration_manager.execute_migration(migration_file)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 50)
    print("ğŸ“Š è¿ç§»ç»“æœæ‘˜è¦")
    print("=" * 50)
    print(f"è¿ç§»ID: {result.migration_id}")
    print(f"çŠ¶æ€: {'âœ… æˆåŠŸ' if result.success else 'âŒ å¤±è´¥'}")
    print(f"å¼€å§‹æ—¶é—´: {result.start_time}")
    print(f"ç»“æŸæ—¶é—´: {result.end_time}")
    print(f"å¤‡ä»½è·¯å¾„: {result.backup_path}")
    
    if result.error_message:
        print(f"é”™è¯¯ä¿¡æ¯: {result.error_message}")
    
    if result.rollback_performed:
        print("ğŸ”„ å·²æ‰§è¡Œäº‹åŠ¡å›æ»š")
    
    # æœ€ç»ˆéªŒè¯
    if result.success:
        verification_success = await migration_manager.verify_migration_success()
        if verification_success:
            print("ğŸ‰ è¿ç§»å®Œå…¨æˆåŠŸï¼Œæ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡ï¼")
        else:
            print("âš ï¸ è¿ç§»å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    
    print("=" * 50)

if __name__ == "__main__":
    asyncio.run(main())