#!/usr/bin/env python3
"""
æ•°æ®åº“æ€§èƒ½è°ƒä¼˜è„šæœ¬
æ‰§è¡Œæ…¢æŸ¥è¯¢åˆ†æã€é…ç½®ä¼˜åŒ–ã€ç›‘æ§è®¾ç½®ç­‰
"""
import asyncio
import json
import os
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.database_optimizer import database_optimizer, run_database_optimization
from app.services.database_monitor import database_monitor, start_database_monitoring

def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    print("=" * 60)
    print("ğŸ—„ï¸  LAWSKERæ•°æ®åº“æ€§èƒ½è°ƒä¼˜")
    print("=" * 60)
    print(f"ğŸ“… æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

def print_section_header(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*20} {title} {'='*20}")

def print_slow_queries(slow_queries):
    """æ‰“å°æ…¢æŸ¥è¯¢åˆ†æç»“æœ"""
    if not slow_queries:
        print("âœ… æœªå‘ç°æ…¢æŸ¥è¯¢")
        return
    
    print(f"âš ï¸  å‘ç° {len(slow_queries)} ä¸ªæ…¢æŸ¥è¯¢:")
    print("-" * 60)
    
    for i, sq in enumerate(slow_queries[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
        query_preview = sq["query"][:100] + "..." if len(sq["query"]) > 100 else sq["query"]
        print(f"{i}. æ‰§è¡Œæ—¶é—´: {sq['duration']:.2f}s")
        print(f"   æŸ¥è¯¢: {query_preview}")
        print(f"   æ—¶é—´: {sq['timestamp']}")
        print()

def print_optimization_suggestions(suggestions):
    """æ‰“å°ä¼˜åŒ–å»ºè®®"""
    if not suggestions:
        print("âœ… æš‚æ— ä¼˜åŒ–å»ºè®®")
        return
    
    # ç´¢å¼•å»ºè®®
    index_recommendations = suggestions.get("index_recommendations", [])
    if index_recommendations:
        print(f"ğŸ“Š ç´¢å¼•ä¼˜åŒ–å»ºè®® ({len(index_recommendations)} é¡¹):")
        for i, rec in enumerate(index_recommendations, 1):
            print(f"  {i}. è¡¨: {rec['table']}")
            print(f"     å­—æ®µ: {', '.join(rec['columns'])}")
            print(f"     SQL: {rec['index_sql']}")
            print(f"     åŸå› : {rec['reason']}")
            print()
    
    # æŸ¥è¯¢é‡å†™å»ºè®®
    query_rewrites = suggestions.get("query_rewrites", [])
    if query_rewrites:
        print(f"ğŸ”„ æŸ¥è¯¢é‡å†™å»ºè®® ({len(query_rewrites)} é¡¹):")
        for i, rewrite in enumerate(query_rewrites, 1):
            print(f"  {i}. é—®é¢˜: {rewrite['issue']}")
            print(f"     å»ºè®®: {rewrite['suggestion']}")
            print(f"     åŸå› : {rewrite['reason']}")
            print()

def print_database_metrics(metrics):
    """æ‰“å°æ•°æ®åº“æŒ‡æ ‡"""
    if not metrics:
        print("âŒ æ— æ³•è·å–æ•°æ®åº“æŒ‡æ ‡")
        return
    
    print("ğŸ“Š å½“å‰æ•°æ®åº“æŒ‡æ ‡:")
    print(f"  ğŸ”— æ´»è·ƒè¿æ¥: {metrics['connections_active']}")
    print(f"  ğŸ”— æ€»è¿æ¥æ•°: {metrics['connections_total']}")
    print(f"  âš¡ æ¯ç§’æŸ¥è¯¢: {metrics['queries_per_second']:.2f}")
    print(f"  ğŸ’¾ ç¼“å­˜å‘½ä¸­ç‡: {metrics['cache_hit_ratio']:.2f}%")
    print(f"  ğŸ’¿ ç£ç›˜ä½¿ç”¨: {metrics['disk_usage_gb']:.2f} GB")
    print(f"  ğŸ§  å†…å­˜ä½¿ç”¨: {metrics['memory_usage_mb']:.2f} MB")
    print(f"  ğŸ–¥ï¸  CPUä½¿ç”¨ç‡: {metrics['cpu_usage_percent']:.2f}%")

def print_configuration_recommendations(config_rec):
    """æ‰“å°é…ç½®å»ºè®®"""
    if config_rec.get("status") != "success":
        print(f"âŒ é…ç½®ä¼˜åŒ–å¤±è´¥: {config_rec.get('message', 'Unknown error')}")
        return
    
    recommendations = config_rec.get("recommendations", {})
    system_info = config_rec.get("system_info", {})
    
    print("âš™ï¸  ç³»ç»Ÿä¿¡æ¯:")
    print(f"  ğŸ’¾ å†…å­˜: {system_info.get('memory_gb', 0):.1f} GB")
    print(f"  ğŸ–¥ï¸  CPUæ ¸å¿ƒ: {system_info.get('cpu_count', 0)}")
    
    print("\nğŸ“ PostgreSQLé…ç½®å»ºè®®:")
    for param, value in recommendations.items():
        print(f"  {param} = {value}")

def save_optimization_report(results: dict):
    """ä¿å­˜ä¼˜åŒ–æŠ¥å‘Š"""
    try:
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = reports_dir / f"database_optimization_report_{timestamp}.json"
        
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ“„ ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # ç”ŸæˆPostgreSQLé…ç½®æ–‡ä»¶
        config_rec = results.get("configuration_recommendations", {})
        if config_rec.get("status") == "success":
            config_file = reports_dir / f"postgresql_optimized_{timestamp}.conf"
            with open(config_file, "w", encoding="utf-8") as f:
                f.write(config_rec.get("config_content", ""))
            print(f"âš™ï¸  PostgreSQLé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {config_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {str(e)}")
        return False

def generate_optimization_summary(results: dict):
    """ç”Ÿæˆä¼˜åŒ–æ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“‹ ä¼˜åŒ–æ‘˜è¦")
    print("="*60)
    
    # æ…¢æŸ¥è¯¢æ‘˜è¦
    slow_queries = results.get("slow_queries", [])
    print(f"ğŸŒ æ…¢æŸ¥è¯¢: {len(slow_queries)} ä¸ª")
    
    # ä¼˜åŒ–å»ºè®®æ‘˜è¦
    suggestions = results.get("optimization_suggestions", {})
    index_count = len(suggestions.get("index_recommendations", []))
    rewrite_count = len(suggestions.get("query_rewrites", []))
    print(f"ğŸ“Š ç´¢å¼•å»ºè®®: {index_count} ä¸ª")
    print(f"ğŸ”„ æŸ¥è¯¢é‡å†™å»ºè®®: {rewrite_count} ä¸ª")
    
    # é…ç½®ä¼˜åŒ–æ‘˜è¦
    config_status = results.get("configuration_recommendations", {}).get("status")
    print(f"âš™ï¸  é…ç½®ä¼˜åŒ–: {'âœ… æˆåŠŸ' if config_status == 'success' else 'âŒ å¤±è´¥'}")
    
    # è¯»å†™åˆ†ç¦»æ‘˜è¦
    rw_status = results.get("read_write_splitting", {}).get("status")
    print(f"ğŸ”„ è¯»å†™åˆ†ç¦»: {'âœ… å·²é…ç½®' if rw_status == 'success' else 'âš ï¸  éœ€è¦é…ç½®'}")
    
    # ç›‘æ§è®¾ç½®æ‘˜è¦
    monitor_status = results.get("monitoring_setup", {}).get("status")
    print(f"ğŸ“Š ç›‘æ§å‘Šè­¦: {'âœ… å·²è®¾ç½®' if monitor_status == 'success' else 'âš ï¸  éœ€è¦è®¾ç½®'}")
    
    # æ€§èƒ½æŒ‡æ ‡æ‘˜è¦
    metrics = results.get("database_metrics", {})
    if metrics:
        cache_hit_ratio = metrics.get("cache_hit_ratio", 0)
        connections_active = metrics.get("connections_active", 0)
        connections_total = metrics.get("connections_total", 1)
        connection_usage = (connections_active / connections_total) * 100
        
        print(f"\nğŸ“ˆ å…³é”®æŒ‡æ ‡:")
        print(f"  ğŸ’¾ ç¼“å­˜å‘½ä¸­ç‡: {cache_hit_ratio:.1f}%")
        print(f"  ğŸ”— è¿æ¥ä½¿ç”¨ç‡: {connection_usage:.1f}%")
        print(f"  âš¡ QPS: {metrics.get('queries_per_second', 0):.1f}")

def print_next_steps():
    """æ‰“å°åç»­æ­¥éª¤"""
    print("\n" + "="*60)
    print("ğŸ“‹ åç»­æ­¥éª¤å»ºè®®")
    print("="*60)
    print("1. ğŸ“Š å®¡æŸ¥ç”Ÿæˆçš„PostgreSQLé…ç½®æ–‡ä»¶")
    print("2. ğŸ”§ åœ¨æµ‹è¯•ç¯å¢ƒä¸­åº”ç”¨é…ç½®æ›´æ”¹")
    print("3. ğŸ“ˆ æ‰§è¡Œæ€§èƒ½æµ‹è¯•éªŒè¯æ”¹è¿›æ•ˆæœ")
    print("4. ğŸ—„ï¸  æ ¹æ®ç´¢å¼•å»ºè®®åˆ›å»ºæ•°æ®åº“ç´¢å¼•")
    print("5. ğŸ”„ é‡å†™è¯†åˆ«å‡ºçš„æ…¢æŸ¥è¯¢")
    print("6. ğŸ“Š å¯åŠ¨æ•°æ®åº“ç›‘æ§æœåŠ¡")
    print("7. âš ï¸  è®¾ç½®å‘Šè­¦é€šçŸ¥æ¸ é“")
    print("8. ğŸ“… å®šæœŸè¿è¡Œæ€§èƒ½åˆ†æ")

async def run_interactive_optimization():
    """è¿è¡Œäº¤äº’å¼ä¼˜åŒ–"""
    print("ğŸš€ å¼€å§‹æ•°æ®åº“æ€§èƒ½åˆ†æ...")
    
    try:
        # è¿è¡Œå®Œæ•´çš„æ€§èƒ½åˆ†æ
        results = await run_database_optimization()
        
        if "error" in results:
            print(f"âŒ æ€§èƒ½åˆ†æå¤±è´¥: {results['error']}")
            return False
        
        # æ˜¾ç¤ºæ…¢æŸ¥è¯¢åˆ†æç»“æœ
        print_section_header("æ…¢æŸ¥è¯¢åˆ†æ")
        print_slow_queries(results.get("slow_queries", []))
        
        # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
        print_section_header("ä¼˜åŒ–å»ºè®®")
        print_optimization_suggestions(results.get("optimization_suggestions", {}))
        
        # æ˜¾ç¤ºæ•°æ®åº“æŒ‡æ ‡
        print_section_header("æ•°æ®åº“æŒ‡æ ‡")
        print_database_metrics(results.get("database_metrics", {}))
        
        # æ˜¾ç¤ºé…ç½®å»ºè®®
        print_section_header("é…ç½®ä¼˜åŒ–")
        print_configuration_recommendations(results.get("configuration_recommendations", {}))
        
        # ä¿å­˜æŠ¥å‘Š
        print_section_header("æŠ¥å‘Šç”Ÿæˆ")
        save_optimization_report(results)
        
        # ç”Ÿæˆæ‘˜è¦
        generate_optimization_summary(results)
        
        # è¯¢é—®æ˜¯å¦å¯åŠ¨ç›‘æ§
        print_section_header("ç›‘æ§æœåŠ¡")
        response = input("æ˜¯å¦å¯åŠ¨æ•°æ®åº“ç›‘æ§æœåŠ¡? (y/N): ").strip().lower()
        
        if response in ['y', 'yes']:
            print("ğŸš€ å¯åŠ¨æ•°æ®åº“ç›‘æ§æœåŠ¡...")
            # åœ¨åå°å¯åŠ¨ç›‘æ§ï¼ˆå®é™…éƒ¨ç½²æ—¶åº”è¯¥ä½¿ç”¨è¿›ç¨‹ç®¡ç†å™¨ï¼‰
            asyncio.create_task(start_database_monitoring())
            print("âœ… æ•°æ®åº“ç›‘æ§æœåŠ¡å·²å¯åŠ¨")
        else:
            print("â„¹ï¸  å¯ä»¥ç¨åæ‰‹åŠ¨å¯åŠ¨ç›‘æ§æœåŠ¡")
        
        # æ˜¾ç¤ºåç»­æ­¥éª¤
        print_next_steps()
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False

async def run_quick_analysis():
    """è¿è¡Œå¿«é€Ÿåˆ†æ"""
    print("âš¡ è¿è¡Œå¿«é€Ÿæ•°æ®åº“åˆ†æ...")
    
    try:
        # åªåˆ†ææ…¢æŸ¥è¯¢å’ŒåŸºç¡€æŒ‡æ ‡
        slow_queries = await database_optimizer.analyze_slow_queries(hours=1)
        metrics = await database_optimizer.collect_database_metrics()
        
        print_section_header("å¿«é€Ÿåˆ†æç»“æœ")
        
        # è½¬æ¢æ…¢æŸ¥è¯¢æ ¼å¼
        slow_queries_dict = [
            {
                "query": sq.query,
                "duration": sq.duration,
                "timestamp": sq.timestamp.isoformat()
            }
            for sq in slow_queries
        ]
        
        print_slow_queries(slow_queries_dict)
        
        # è½¬æ¢æŒ‡æ ‡æ ¼å¼
        metrics_dict = {
            "connections_active": metrics.connections_active,
            "connections_total": metrics.connections_total,
            "queries_per_second": metrics.queries_per_second,
            "cache_hit_ratio": metrics.cache_hit_ratio,
            "disk_usage_gb": metrics.disk_usage_gb,
            "memory_usage_mb": metrics.memory_usage_mb,
            "cpu_usage_percent": metrics.cpu_usage_percent
        }
        
        print_database_metrics(metrics_dict)
        
        return True
        
    except Exception as e:
        print(f"âŒ å¿«é€Ÿåˆ†æå¤±è´¥: {str(e)}")
        return False

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print("æ•°æ®åº“æ€§èƒ½è°ƒä¼˜å·¥å…·")
    print("\nç”¨æ³•:")
    print("  python run_database_optimization.py [é€‰é¡¹]")
    print("\né€‰é¡¹:")
    print("  --full, -f     è¿è¡Œå®Œæ•´çš„æ€§èƒ½åˆ†æå’Œä¼˜åŒ–")
    print("  --quick, -q    è¿è¡Œå¿«é€Ÿåˆ†æ")
    print("  --monitor, -m  å¯åŠ¨ç›‘æ§æœåŠ¡")
    print("  --help, -h     æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
    print("\nç¤ºä¾‹:")
    print("  python run_database_optimization.py --full")
    print("  python run_database_optimization.py --quick")

async def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = sys.argv[1:]
    
    if not args or "--help" in args or "-h" in args:
        show_help()
        return
    
    try:
        if "--full" in args or "-f" in args:
            success = await run_interactive_optimization()
        elif "--quick" in args or "-q" in args:
            success = await run_quick_analysis()
        elif "--monitor" in args or "-m" in args:
            print("ğŸš€ å¯åŠ¨æ•°æ®åº“ç›‘æ§æœåŠ¡...")
            await start_database_monitoring()
            success = True
        else:
            print("âŒ æœªçŸ¥é€‰é¡¹ï¼Œä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©")
            success = False
        
        if success:
            print("\nâœ… æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")
            sys.exit(0)
        else:
            print("\nâŒ æ•°æ®åº“ä¼˜åŒ–å¤±è´¥")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())