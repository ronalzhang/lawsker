#!/usr/bin/env python3
"""
è½¬åŒ–ç‡ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•è„šæœ¬
Test script for conversion optimization system

Tests the implementation of user registration conversion rate optimization
to achieve the 40% improvement target.
"""

import asyncio
import sys
import os
from datetime import datetime, timedelta
from typing import Dict, Any

# Add the backend directory to Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.core.database import get_db
from app.services.conversion_optimization_service import ConversionOptimizationService, get_conversion_optimization_config
from sqlalchemy.orm import Session


class ConversionOptimizationTester:
    """è½¬åŒ–ç‡ä¼˜åŒ–æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.db = None
        self.service = None
        self.test_results = []
    
    async def setup(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # For testing, we'll create a mock service without database dependency
        self.service = ConversionOptimizationService(None)
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹è½¬åŒ–ç‡ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•...")
        print("=" * 60)
        
        # Setup test environment
        await self.setup()
        
        # Test 1: Configuration
        await self.test_optimization_config()
        
        # Test 2: Event Tracking
        await self.test_event_tracking()
        
        # Test 3: Metrics Calculation
        await self.test_metrics_calculation()
        
        # Test 4: Recommendations
        await self.test_recommendations()
        
        # Test 5: Funnel Analysis
        await self.test_funnel_analysis()
        
        # Test 6: Conversion Report
        await self.test_conversion_report()
        
        # Test 7: A/B Testing
        await self.test_ab_testing()
        
        # Test 8: Simulation
        await self.test_conversion_simulation()
        
        # Summary
        self.print_test_summary()
    
    async def test_optimization_config(self):
        """æµ‹è¯•ä¼˜åŒ–é…ç½®"""
        print("\nğŸ“‹ æµ‹è¯• 1: ä¼˜åŒ–é…ç½®")
        
        try:
            config = get_conversion_optimization_config()
            
            # Verify required config keys
            required_keys = [
                'target_improvement',
                'baseline_conversion_rate',
                'target_conversion_rate',
                'demo_conversion_target',
                'ab_test_variants',
                'tracking_events'
            ]
            
            for key in required_keys:
                assert key in config, f"Missing config key: {key}"
            
            # Verify target improvement is 40%
            assert config['target_improvement'] == 40.0, "Target improvement should be 40%"
            
            # Verify target conversion rate calculation
            baseline = config['baseline_conversion_rate']
            target = config['target_conversion_rate']
            expected_target = baseline * 1.4  # 40% improvement
            assert abs(target - expected_target) < 0.1, f"Target rate calculation incorrect: {target} vs {expected_target}"
            
            print("âœ… ä¼˜åŒ–é…ç½®æµ‹è¯•é€šè¿‡")
            print(f"   - ç›®æ ‡æ”¹è¿›: {config['target_improvement']}%")
            print(f"   - åŸºçº¿è½¬åŒ–ç‡: {config['baseline_conversion_rate']}%")
            print(f"   - ç›®æ ‡è½¬åŒ–ç‡: {config['target_conversion_rate']}%")
            print(f"   - A/Bæµ‹è¯•å˜ä½“: {len(config['ab_test_variants'])}ä¸ª")
            print(f"   - è·Ÿè¸ªäº‹ä»¶: {len(config['tracking_events'])}ä¸ª")
            
            self.test_results.append(("ä¼˜åŒ–é…ç½®", True, "é…ç½®æ­£ç¡®"))
            
        except Exception as e:
            print(f"âŒ ä¼˜åŒ–é…ç½®æµ‹è¯•å¤±è´¥: {str(e)}")
            self.test_results.append(("ä¼˜åŒ–é…ç½®", False, str(e)))
    
    async def test_event_tracking(self):
        """æµ‹è¯•äº‹ä»¶è·Ÿè¸ª"""
        print("\nğŸ“Š æµ‹è¯• 2: äº‹ä»¶è·Ÿè¸ª")
        
        try:
            # Test tracking different events
            events_to_test = [
                ('page_load', None, 'test_session_1', {'source': 'direct'}),
                ('demo_start', None, 'test_session_1', {'demo_type': 'user'}),
                ('registration_attempt', 'test_user_1', 'test_session_1', {'identity_type': 'user'}),
                ('registration_success', 'test_user_1', 'test_session_1', {'identity_type': 'user'})
            ]
            
            for event_type, user_id, session_id, metadata in events_to_test:
                result = await self.service.track_conversion_event(
                    event_type=event_type,
                    user_id=user_id,
                    session_id=session_id,
                    metadata=metadata
                )
                
                assert result['event_type'] == event_type, f"Event type mismatch: {result['event_type']}"
                assert result['user_id'] == user_id, f"User ID mismatch: {result['user_id']}"
                assert result['session_id'] == session_id, f"Session ID mismatch: {result['session_id']}"
                assert result['metadata'] == metadata, f"Metadata mismatch: {result['metadata']}"
            
            print("âœ… äº‹ä»¶è·Ÿè¸ªæµ‹è¯•é€šè¿‡")
            print(f"   - æˆåŠŸè·Ÿè¸ª {len(events_to_test)} ä¸ªäº‹ä»¶")
            print("   - äº‹ä»¶ç±»å‹: page_load, demo_start, registration_attempt, registration_success")
            
            self.test_results.append(("äº‹ä»¶è·Ÿè¸ª", True, f"è·Ÿè¸ªäº†{len(events_to_test)}ä¸ªäº‹ä»¶"))
            
        except Exception as e:
            print(f"âŒ äº‹ä»¶è·Ÿè¸ªæµ‹è¯•å¤±è´¥: {str(e)}")
            self.test_results.append(("äº‹ä»¶è·Ÿè¸ª", False, str(e)))
    
    async def test_metrics_calculation(self):
        """æµ‹è¯•æŒ‡æ ‡è®¡ç®—"""
        print("\nğŸ“ˆ æµ‹è¯• 3: æŒ‡æ ‡è®¡ç®—")
        
        try:
            # Get metrics for the last 30 days
            metrics = await self.service.get_conversion_metrics()
            
            # Verify metrics structure
            required_keys = ['period', 'metrics', 'targets']
            for key in required_keys:
                assert key in metrics, f"Missing metrics key: {key}"
            
            # Verify metrics data
            metrics_data = metrics['metrics']
            required_metrics = [
                'total_visitors',
                'total_registrations',
                'demo_users',
                'demo_conversions',
                'registration_conversion_rate',
                'demo_conversion_rate'
            ]
            
            for metric in required_metrics:
                assert metric in metrics_data, f"Missing metric: {metric}"
                assert isinstance(metrics_data[metric], (int, float)), f"Invalid metric type: {metric}"
            
            # Verify targets
            targets = metrics['targets']
            assert 'registration_rate_target' in targets, "Missing registration rate target"
            assert 'demo_conversion_target' in targets, "Missing demo conversion target"
            
            print("âœ… æŒ‡æ ‡è®¡ç®—æµ‹è¯•é€šè¿‡")
            print(f"   - æ€»è®¿é—®è€…: {metrics_data['total_visitors']}")
            print(f"   - æ€»æ³¨å†Œæ•°: {metrics_data['total_registrations']}")
            print(f"   - å½“å‰è½¬åŒ–ç‡: {metrics_data['registration_conversion_rate']}%")
            print(f"   - ç›®æ ‡è½¬åŒ–ç‡: {targets['registration_rate_target']}%")
            print(f"   - æ¼”ç¤ºè½¬åŒ–ç‡: {metrics_data['demo_conversion_rate']}%")
            
            self.test_results.append(("æŒ‡æ ‡è®¡ç®—", True, f"è½¬åŒ–ç‡: {metrics_data['registration_conversion_rate']}%"))
            
        except Exception as e:
            print(f"âŒ æŒ‡æ ‡è®¡ç®—æµ‹è¯•å¤±è´¥: {str(e)}")
            self.test_results.append(("æŒ‡æ ‡è®¡ç®—", False, str(e)))
    
    async def test_recommendations(self):
        """æµ‹è¯•ä¼˜åŒ–å»ºè®®"""
        print("\nğŸ’¡ æµ‹è¯• 4: ä¼˜åŒ–å»ºè®®")
        
        try:
            recommendations = await self.service.get_optimization_recommendations()
            
            assert isinstance(recommendations, list), "Recommendations should be a list"
            
            for rec in recommendations:
                required_keys = ['type', 'priority', 'title', 'description', 'actions']
                for key in required_keys:
                    assert key in rec, f"Missing recommendation key: {key}"
                
                assert rec['priority'] in ['high', 'medium', 'low'], f"Invalid priority: {rec['priority']}"
                assert isinstance(rec['actions'], list), "Actions should be a list"
                assert len(rec['actions']) > 0, "Actions list should not be empty"
            
            print("âœ… ä¼˜åŒ–å»ºè®®æµ‹è¯•é€šè¿‡")
            print(f"   - ç”Ÿæˆäº† {len(recommendations)} æ¡å»ºè®®")
            
            for i, rec in enumerate(recommendations[:3], 1):  # Show first 3
                print(f"   {i}. [{rec['priority'].upper()}] {rec['title']}")
                print(f"      {rec['description']}")
            
            self.test_results.append(("ä¼˜åŒ–å»ºè®®", True, f"ç”Ÿæˆäº†{len(recommendations)}æ¡å»ºè®®"))
            
        except Exception as e:
            print(f"âŒ ä¼˜åŒ–å»ºè®®æµ‹è¯•å¤±è´¥: {str(e)}")
            self.test_results.append(("ä¼˜åŒ–å»ºè®®", False, str(e)))
    
    async def test_funnel_analysis(self):
        """æµ‹è¯•æ¼æ–—åˆ†æ"""
        print("\nğŸ” æµ‹è¯• 5: æ¼æ–—åˆ†æ")
        
        try:
            analysis = await self.service.get_registration_funnel_analysis()
            
            # Verify analysis structure
            required_keys = ['funnel_data', 'conversion_rates', 'overall_conversion_rate', 'bottlenecks']
            for key in required_keys:
                assert key in analysis, f"Missing analysis key: {key}"
            
            # Verify funnel data
            funnel_data = analysis['funnel_data']
            assert isinstance(funnel_data, dict), "Funnel data should be a dict"
            assert len(funnel_data) > 0, "Funnel data should not be empty"
            
            # Verify conversion rates
            conversion_rates = analysis['conversion_rates']
            assert isinstance(conversion_rates, dict), "Conversion rates should be a dict"
            
            # Verify overall rate
            overall_rate = analysis['overall_conversion_rate']
            assert isinstance(overall_rate, (int, float)), "Overall rate should be numeric"
            assert 0 <= overall_rate <= 100, "Overall rate should be between 0 and 100"
            
            # Verify bottlenecks
            bottlenecks = analysis['bottlenecks']
            assert isinstance(bottlenecks, list), "Bottlenecks should be a list"
            
            print("âœ… æ¼æ–—åˆ†ææµ‹è¯•é€šè¿‡")
            print(f"   - æ•´ä½“è½¬åŒ–ç‡: {overall_rate}%")
            print(f"   - æ¼æ–—æ­¥éª¤: {len(funnel_data)}ä¸ª")
            print(f"   - è¯†åˆ«ç“¶é¢ˆ: {len(bottlenecks)}ä¸ª")
            
            # Show funnel steps
            for step, value in list(funnel_data.items())[:3]:
                print(f"   - {step.replace('_', ' ').title()}: {value}")
            
            self.test_results.append(("æ¼æ–—åˆ†æ", True, f"æ•´ä½“è½¬åŒ–ç‡: {overall_rate}%"))
            
        except Exception as e:
            print(f"âŒ æ¼æ–—åˆ†ææµ‹è¯•å¤±è´¥: {str(e)}")
            self.test_results.append(("æ¼æ–—åˆ†æ", False, str(e)))
    
    async def test_conversion_report(self):
        """æµ‹è¯•è½¬åŒ–ç‡æŠ¥å‘Š"""
        print("\nğŸ“‹ æµ‹è¯• 6: è½¬åŒ–ç‡æŠ¥å‘Š")
        
        try:
            report = await self.service.generate_conversion_report()
            
            # Verify report structure
            required_keys = [
                'report_date',
                'current_month',
                'last_month',
                'improvement',
                'recommendations',
                'next_actions'
            ]
            
            for key in required_keys:
                assert key in report, f"Missing report key: {key}"
            
            # Verify improvement data
            improvement = report['improvement']
            required_improvement_keys = ['percentage', 'target_achieved', 'target_progress']
            for key in required_improvement_keys:
                assert key in improvement, f"Missing improvement key: {key}"
            
            # Verify recommendations
            recommendations = report['recommendations']
            assert isinstance(recommendations, list), "Recommendations should be a list"
            
            # Verify next actions
            next_actions = report['next_actions']
            assert isinstance(next_actions, list), "Next actions should be a list"
            assert len(next_actions) > 0, "Next actions should not be empty"
            
            print("âœ… è½¬åŒ–ç‡æŠ¥å‘Šæµ‹è¯•é€šè¿‡")
            print(f"   - æŠ¥å‘Šæ—¥æœŸ: {report['report_date'][:10]}")
            print(f"   - æ”¹è¿›ç™¾åˆ†æ¯”: {improvement['percentage']}%")
            print(f"   - ç›®æ ‡è¾¾æˆ: {'æ˜¯' if improvement['target_achieved'] else 'å¦'}")
            print(f"   - ç›®æ ‡è¿›åº¦: {improvement['target_progress']:.1f}%")
            print(f"   - å»ºè®®æ•°é‡: {len(recommendations)}")
            print(f"   - ä¸‹ä¸€æ­¥è¡ŒåŠ¨: {len(next_actions)}é¡¹")
            
            self.test_results.append(("è½¬åŒ–ç‡æŠ¥å‘Š", True, f"æ”¹è¿›: {improvement['percentage']}%"))
            
        except Exception as e:
            print(f"âŒ è½¬åŒ–ç‡æŠ¥å‘Šæµ‹è¯•å¤±è´¥: {str(e)}")
            self.test_results.append(("è½¬åŒ–ç‡æŠ¥å‘Š", False, str(e)))
    
    async def test_ab_testing(self):
        """æµ‹è¯•A/Bæµ‹è¯•"""
        print("\nğŸ§ª æµ‹è¯• 7: A/Bæµ‹è¯•")
        
        try:
            # Test A/B test result tracking
            test_cases = [
                ('registration_flow_test', 'original', 'user_1', False, {'time_spent': 120}),
                ('registration_flow_test', 'streamlined_2_step', 'user_2', True, {'time_spent': 80}),
                ('demo_prominence_test', 'demo_prominent', 'user_3', True, {'demo_used': True}),
                ('trust_indicators_test', 'trust_indicators', 'user_4', True, {'trust_score': 8})
            ]
            
            for test_name, variant, user_id, converted, metadata in test_cases:
                result = await self.service.track_ab_test_result(
                    test_name=test_name,
                    variant=variant,
                    user_id=user_id,
                    converted=converted,
                    metadata=metadata
                )
                
                assert result['test_name'] == test_name, f"Test name mismatch: {result['test_name']}"
                assert result['variant'] == variant, f"Variant mismatch: {result['variant']}"
                assert result['user_id'] == user_id, f"User ID mismatch: {result['user_id']}"
                assert result['converted'] == converted, f"Converted mismatch: {result['converted']}"
            
            print("âœ… A/Bæµ‹è¯•è·Ÿè¸ªé€šè¿‡")
            print(f"   - æµ‹è¯•äº† {len(test_cases)} ä¸ªA/Bæµ‹è¯•ç»“æœ")
            print("   - æµ‹è¯•ç±»å‹: registration_flow, demo_prominence, trust_indicators")
            
            # Calculate conversion rates by variant
            variants_tested = {}
            for test_name, variant, user_id, converted, metadata in test_cases:
                if variant not in variants_tested:
                    variants_tested[variant] = {'total': 0, 'converted': 0}
                variants_tested[variant]['total'] += 1
                if converted:
                    variants_tested[variant]['converted'] += 1
            
            print("   - å˜ä½“è½¬åŒ–ç‡:")
            for variant, data in variants_tested.items():
                rate = (data['converted'] / data['total']) * 100 if data['total'] > 0 else 0
                print(f"     {variant}: {rate:.1f}% ({data['converted']}/{data['total']})")
            
            self.test_results.append(("A/Bæµ‹è¯•", True, f"æµ‹è¯•äº†{len(test_cases)}ä¸ªç»“æœ"))
            
        except Exception as e:
            print(f"âŒ A/Bæµ‹è¯•å¤±è´¥: {str(e)}")
            self.test_results.append(("A/Bæµ‹è¯•", False, str(e)))
    
    async def test_conversion_simulation(self):
        """æµ‹è¯•è½¬åŒ–ç‡æ¨¡æ‹Ÿ"""
        print("\nğŸ¯ æµ‹è¯• 8: è½¬åŒ–ç‡æ¨¡æ‹Ÿ")
        
        try:
            # Simulate conversion improvement calculation
            from app.services.conversion_optimization_service import calculate_conversion_improvement
            
            # Test cases
            test_cases = [
                (10.0, 14.0, 40.0),  # 40% improvement
                (8.5, 12.75, 50.0),  # 50% improvement
                (12.0, 15.6, 30.0),  # 30% improvement
            ]
            
            for baseline, current, expected_improvement in test_cases:
                actual_improvement = calculate_conversion_improvement(baseline, current)
                assert abs(actual_improvement - expected_improvement) < 0.1, \
                    f"Improvement calculation error: {actual_improvement} vs {expected_improvement}"
            
            print("âœ… è½¬åŒ–ç‡æ¨¡æ‹Ÿæµ‹è¯•é€šè¿‡")
            print("   - æ”¹è¿›è®¡ç®—å…¬å¼æ­£ç¡®")
            print("   - æµ‹è¯•ç”¨ä¾‹:")
            for baseline, current, expected in test_cases:
                actual = calculate_conversion_improvement(baseline, current)
                print(f"     {baseline}% â†’ {current}% = {actual:.1f}% æ”¹è¿›")
            
            # Test target achievement
            config = get_conversion_optimization_config()
            baseline = config['baseline_conversion_rate']
            target = config['target_conversion_rate']
            target_improvement = calculate_conversion_improvement(baseline, target)
            
            print(f"   - ç›®æ ‡æ”¹è¿›: {baseline}% â†’ {target}% = {target_improvement:.1f}%")
            
            self.test_results.append(("è½¬åŒ–ç‡æ¨¡æ‹Ÿ", True, f"ç›®æ ‡æ”¹è¿›: {target_improvement:.1f}%"))
            
        except Exception as e:
            print(f"âŒ è½¬åŒ–ç‡æ¨¡æ‹Ÿæµ‹è¯•å¤±è´¥: {str(e)}")
            self.test_results.append(("è½¬åŒ–ç‡æ¨¡æ‹Ÿ", False, str(e)))
    
    def print_test_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "=" * 60)
        print("ğŸ“Š è½¬åŒ–ç‡ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•æ€»ç»“")
        print("=" * 60)
        
        passed = sum(1 for _, success, _ in self.test_results if success)
        total = len(self.test_results)
        
        print(f"æ€»æµ‹è¯•æ•°: {total}")
        print(f"é€šè¿‡æµ‹è¯•: {passed}")
        print(f"å¤±è´¥æµ‹è¯•: {total - passed}")
        print(f"æˆåŠŸç‡: {(passed/total)*100:.1f}%")
        
        print("\nè¯¦ç»†ç»“æœ:")
        for test_name, success, details in self.test_results:
            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            print(f"  {status} {test_name}: {details}")
        
        if passed == total:
            print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è½¬åŒ–ç‡ä¼˜åŒ–ç³»ç»Ÿå®æ–½æˆåŠŸï¼")
            print("\nğŸ“ˆ ç³»ç»ŸåŠŸèƒ½:")
            print("  âœ… äº‹ä»¶è·Ÿè¸ªå’Œåˆ†æ")
            print("  âœ… è½¬åŒ–ç‡æŒ‡æ ‡è®¡ç®—")
            print("  âœ… ä¼˜åŒ–å»ºè®®ç”Ÿæˆ")
            print("  âœ… æ³¨å†Œæ¼æ–—åˆ†æ")
            print("  âœ… A/Bæµ‹è¯•æ”¯æŒ")
            print("  âœ… è½¬åŒ–ç‡æŠ¥å‘Š")
            print("  âœ… æ”¹è¿›æ¨¡æ‹Ÿè®¡ç®—")
            
            print("\nğŸ¯ ä¼˜åŒ–ç›®æ ‡:")
            config = get_conversion_optimization_config()
            print(f"  - åŸºçº¿è½¬åŒ–ç‡: {config['baseline_conversion_rate']}%")
            print(f"  - ç›®æ ‡è½¬åŒ–ç‡: {config['target_conversion_rate']}%")
            print(f"  - ç›®æ ‡æ”¹è¿›: {config['target_improvement']}%")
            
            print("\nğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
            print("  1. éƒ¨ç½²ä¼˜åŒ–ç‰ˆæ³¨å†Œé¡µé¢ (unified-auth-optimized.html)")
            print("  2. å¯ç”¨è½¬åŒ–ç‡ç›‘æ§ä»ªè¡¨ç›˜")
            print("  3. å¼€å§‹A/Bæµ‹è¯•ä¸åŒçš„æ³¨å†Œæµç¨‹")
            print("  4. ç›‘æ§è½¬åŒ–ç‡æ”¹è¿›è¿›åº¦")
            print("  5. æ ¹æ®æ•°æ®è°ƒæ•´ä¼˜åŒ–ç­–ç•¥")
        else:
            print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®æ–½çŠ¶æ€")


async def main():
    """ä¸»å‡½æ•°"""
    tester = ConversionOptimizationTester()
    await tester.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())