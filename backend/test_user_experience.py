#!/usr/bin/env python3
"""
ç”¨æˆ·ä½“éªŒæµ‹è¯•å’Œä¼˜åŒ–è„šæœ¬
æµ‹è¯•ç•Œé¢å¯ç”¨æ€§ã€é¡µé¢åŠ è½½é€Ÿåº¦ã€ç§»åŠ¨ç«¯ä½“éªŒç­‰
"""
import asyncio
import aiohttp
import time
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.core.logging import get_logger

logger = get_logger(__name__)

@dataclass
class UXTestResult:
    """ç”¨æˆ·ä½“éªŒæµ‹è¯•ç»“æœ"""
    test_name: str
    test_category: str
    score: float  # 0-100åˆ†
    status: str  # excellent, good, fair, poor
    message: str
    details: Dict[str, Any]
    recommendations: List[str]
    timestamp: datetime
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['timestamp'] = self.timestamp.isoformat()
        return result

class UserExperienceTester:
    """ç”¨æˆ·ä½“éªŒæµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.test_results: List[UXTestResult] = []
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def add_test_result(self, test_name: str, category: str, score: float, message: str, 
                       details: Dict[str, Any] = None, recommendations: List[str] = None):
        """æ·»åŠ æµ‹è¯•ç»“æœ"""
        # æ ¹æ®åˆ†æ•°ç¡®å®šçŠ¶æ€
        if score >= 90:
            status = "excellent"
        elif score >= 75:
            status = "good"
        elif score >= 60:
            status = "fair"
        else:
            status = "poor"
        
        result = UXTestResult(
            test_name=test_name,
            test_category=category,
            score=score,
            status=status,
            message=message,
            details=details or {},
            recommendations=recommendations or [],
            timestamp=datetime.now()
        )
        self.test_results.append(result)
        
        status_icon = {"excellent": "ğŸ¯", "good": "âœ…", "fair": "âš ï¸", "poor": "âŒ"}[status]
        logger.info(f"{status_icon} {test_name}: {score:.1f}/100 - {message}")
    
    async def test_page_load_performance(self) -> None:
        """æµ‹è¯•é¡µé¢åŠ è½½æ€§èƒ½"""
        pages = [
            ("/", "é¦–é¡µ"),
            ("/login.html", "ç™»å½•é¡µ"),
            ("/dashboard.html", "ä»ªè¡¨ç›˜"),
            ("/lawyer-workspace.html", "å¾‹å¸ˆå·¥ä½œå°"),
            ("/user-workspace.html", "ç”¨æˆ·å·¥ä½œå°")
        ]
        
        for page_path, page_name in pages:
            try:
                start_time = time.time()
                
                async with self.session.get(f"{self.base_url}{page_path}") as response:
                    content = await response.text()
                    load_time = time.time() - start_time
                    
                    # åˆ†æé¡µé¢å¤§å°
                    page_size = len(content.encode('utf-8'))
                    
                    # è®¡ç®—æ€§èƒ½åˆ†æ•°
                    if load_time <= 1.0:
                        time_score = 100
                    elif load_time <= 2.0:
                        time_score = 80
                    elif load_time <= 3.0:
                        time_score = 60
                    else:
                        time_score = 40
                    
                    # é¡µé¢å¤§å°è¯„åˆ†
                    if page_size <= 100 * 1024:  # 100KB
                        size_score = 100
                    elif page_size <= 500 * 1024:  # 500KB
                        size_score = 80
                    elif page_size <= 1024 * 1024:  # 1MB
                        size_score = 60
                    else:
                        size_score = 40
                    
                    overall_score = (time_score + size_score) / 2
                    
                    recommendations = []
                    if load_time > 2.0:
                        recommendations.append("ä¼˜åŒ–æœåŠ¡å™¨å“åº”æ—¶é—´")
                    if page_size > 500 * 1024:
                        recommendations.append("å‹ç¼©é™æ€èµ„æº")
                        recommendations.append("å¯ç”¨Gzipå‹ç¼©")
                    if load_time > 1.0:
                        recommendations.append("ä½¿ç”¨CDNåŠ é€Ÿ")
                    
                    self.add_test_result(
                        f"é¡µé¢åŠ è½½æ€§èƒ½: {page_name}",
                        "performance",
                        overall_score,
                        f"åŠ è½½æ—¶é—´: {load_time:.2f}s, é¡µé¢å¤§å°: {page_size/1024:.1f}KB",
                        {
                            "load_time": load_time,
                            "page_size_bytes": page_size,
                            "page_size_kb": page_size / 1024,
                            "status_code": response.status
                        },
                        recommendations
                    )
                    
            except Exception as e:
                self.add_test_result(
                    f"é¡µé¢åŠ è½½æ€§èƒ½: {page_name}",
                    "performance",
                    0,
                    f"é¡µé¢åŠ è½½å¤±è´¥: {str(e)}",
                    {"error": str(e)},
                    ["æ£€æŸ¥é¡µé¢æ˜¯å¦å­˜åœ¨", "ä¿®å¤æœåŠ¡å™¨é”™è¯¯"]
                )
    
    async def test_mobile_responsiveness(self) -> None:
        """æµ‹è¯•ç§»åŠ¨ç«¯å“åº”å¼è®¾è®¡"""
        # æ¨¡æ‹Ÿä¸åŒè®¾å¤‡çš„ç”¨æˆ·ä»£ç†
        devices = [
            ("iPhone", "Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X)"),
            ("Android", "Mozilla/5.0 (Linux; Android 10; SM-G975F)"),
            ("iPad", "Mozilla/5.0 (iPad; CPU OS 14_0 like Mac OS X)")
        ]
        
        pages = ["/", "/login.html", "/dashboard.html"]
        
        for device_name, user_agent in devices:
            device_scores = []
            all_checks = []
            
            for page in pages:
                try:
                    headers = {"User-Agent": user_agent}
                    
                    async with self.session.get(f"{self.base_url}{page}", headers=headers) as response:
                        content = await response.text()
                        
                        # æ£€æŸ¥å“åº”å¼è®¾è®¡å…ƒç´ 
                        responsive_score = 0
                        checks = []
                        
                        # æ£€æŸ¥viewport metaæ ‡ç­¾ - æ›´ä¸¥æ ¼çš„æ£€æŸ¥
                        viewport_patterns = [
                            'name="viewport"',
                            'width=device-width',
                            'initial-scale=1.0'
                        ]
                        viewport_found = sum(1 for pattern in viewport_patterns if pattern in content)
                        if viewport_found >= 2:
                            responsive_score += 30
                            checks.append("âœ… å®Œæ•´çš„Viewport metaæ ‡ç­¾")
                        elif viewport_found >= 1:
                            responsive_score += 15
                            checks.append("âš ï¸ éƒ¨åˆ†Viewport metaæ ‡ç­¾")
                        else:
                            checks.append("âŒ ç¼ºå°‘Viewport metaæ ‡ç­¾")
                        
                        # æ£€æŸ¥åª’ä½“æŸ¥è¯¢ - æ›´è¯¦ç»†çš„æ£€æŸ¥
                        media_query_patterns = [
                            '@media',
                            'min-width',
                            'max-width',
                            'screen and'
                        ]
                        media_queries_found = sum(1 for pattern in media_query_patterns if pattern in content)
                        if media_queries_found >= 3:
                            responsive_score += 30
                            checks.append("âœ… å®Œæ•´çš„åª’ä½“æŸ¥è¯¢")
                        elif media_queries_found >= 1:
                            responsive_score += 15
                            checks.append("âš ï¸ åŸºç¡€åª’ä½“æŸ¥è¯¢")
                        else:
                            checks.append("âŒ ç¼ºå°‘åª’ä½“æŸ¥è¯¢")
                        
                        # æ£€æŸ¥å“åº”å¼æ¡†æ¶å’ŒæŠ€æœ¯
                        responsive_tech = [
                            'flexbox', 'flex', 'grid', 'bootstrap', 'tailwind',
                            'container-responsive', 'row-responsive', 'col-responsive'
                        ]
                        tech_found = sum(1 for tech in responsive_tech if tech in content.lower())
                        if tech_found >= 3:
                            responsive_score += 25
                            checks.append("âœ… ç°ä»£å“åº”å¼æŠ€æœ¯")
                        elif tech_found >= 1:
                            responsive_score += 12
                            checks.append("âš ï¸ åŸºç¡€å“åº”å¼æŠ€æœ¯")
                        else:
                            checks.append("âŒ æœªä½¿ç”¨å“åº”å¼æ¡†æ¶")
                        
                        # æ£€æŸ¥ç§»åŠ¨ç«¯ä¼˜åŒ–ç‰¹æ€§
                        mobile_features = [
                            'touch', 'mobile', 'tap-highlight', 'user-scalable=no',
                            'apple-mobile-web-app', 'format-detection', 'min-height: 44px'
                        ]
                        mobile_found = sum(1 for feature in mobile_features if feature in content.lower())
                        if mobile_found >= 3:
                            responsive_score += 15
                            checks.append("âœ… ç§»åŠ¨ç«¯ä¼˜åŒ–å®Œæ•´")
                        elif mobile_found >= 1:
                            responsive_score += 8
                            checks.append("âš ï¸ åŸºç¡€ç§»åŠ¨ç«¯ä¼˜åŒ–")
                        else:
                            checks.append("âŒ ç¼ºå°‘ç§»åŠ¨ç«¯ä¼˜åŒ–")
                        
                        device_scores.append(responsive_score)
                        all_checks.extend(checks)
                        
                except Exception:
                    device_scores.append(0)
                    all_checks.append("âŒ é¡µé¢è®¿é—®å¤±è´¥")
            
            avg_score = sum(device_scores) / len(device_scores) if device_scores else 0
            
            recommendations = []
            if avg_score < 85:
                recommendations.extend([
                    "æ·»åŠ å®Œæ•´çš„viewport metaæ ‡ç­¾é…ç½®",
                    "å®æ–½ç§»åŠ¨ç«¯ä¼˜å…ˆçš„å“åº”å¼è®¾è®¡",
                    "ä½¿ç”¨ç°ä»£CSS Gridå’ŒFlexboxå¸ƒå±€",
                    "ä¼˜åŒ–è§¦æ‘¸äº¤äº’ä½“éªŒï¼ˆæœ€å°44pxè§¦æ‘¸ç›®æ ‡ï¼‰",
                    "æ·»åŠ ç§»åŠ¨ç«¯ä¸“ç”¨çš„CSSæ ·å¼",
                    "å®æ–½æ¸è¿›å¼Webåº”ç”¨(PWA)ç‰¹æ€§"
                ])
            
            self.add_test_result(
                f"ç§»åŠ¨ç«¯å“åº”å¼: {device_name}",
                "mobile",
                avg_score,
                f"å“åº”å¼è®¾è®¡è¯„åˆ†: {avg_score:.1f}/100",
                {
                    "device": device_name,
                    "user_agent": user_agent,
                    "page_scores": device_scores,
                    "checks": all_checks
                },
                recommendations
            )
    
    async def test_accessibility(self) -> None:
        """æµ‹è¯•å¯è®¿é—®æ€§ - å¢å¼ºç‰ˆ"""
        pages = ["/", "/login.html", "/dashboard.html"]
        
        for page in pages:
            try:
                async with self.session.get(f"{self.base_url}{page}") as response:
                    content = await response.text()
                    
                    accessibility_score = 0
                    checks = []
                    
                    # 1. æ£€æŸ¥å›¾ç‰‡altå±æ€§ (25åˆ†)
                    img_count = content.count('<img')
                    alt_count = content.count('alt=')
                    empty_alt_count = content.count('alt=""')
                    
                    if img_count > 0:
                        alt_ratio = alt_count / img_count
                        if alt_ratio >= 0.95:
                            accessibility_score += 25
                            checks.append("âœ… å›¾ç‰‡altå±æ€§å®Œæ•´")
                        elif alt_ratio >= 0.8:
                            accessibility_score += 20
                            checks.append(f"âš ï¸ å›¾ç‰‡altå±æ€§è¦†ç›–ç‡: {alt_ratio*100:.1f}%")
                        else:
                            accessibility_score += 10
                            checks.append(f"âŒ å›¾ç‰‡altå±æ€§è¦†ç›–ç‡ä½: {alt_ratio*100:.1f}%")
                    else:
                        accessibility_score += 25
                        checks.append("âœ… æ— å›¾ç‰‡æˆ–å·²å¤„ç†")
                    
                    # 2. æ£€æŸ¥è¯­ä¹‰åŒ–HTMLæ ‡ç­¾ (20åˆ†)
                    semantic_tags = ['header', 'nav', 'main', 'section', 'article', 'aside', 'footer']
                    semantic_count = sum(1 for tag in semantic_tags if f'<{tag}' in content)
                    
                    # æ£€æŸ¥ARIAæ ‡ç­¾
                    aria_labels = ['role=', 'aria-label=', 'aria-labelledby=', 'aria-describedby=']
                    aria_count = sum(1 for aria in aria_labels if aria in content)
                    
                    if semantic_count >= 4 and aria_count >= 2:
                        accessibility_score += 20
                        checks.append("âœ… è¯­ä¹‰åŒ–æ ‡ç­¾å’ŒARIAæ ‡ç­¾å®Œæ•´")
                    elif semantic_count >= 3:
                        accessibility_score += 15
                        checks.append("âš ï¸ è¯­ä¹‰åŒ–æ ‡ç­¾åŸºæœ¬å®Œæ•´")
                    else:
                        accessibility_score += 5
                        checks.append("âŒ ç¼ºå°‘è¯­ä¹‰åŒ–æ ‡ç­¾")
                    
                    # 3. æ£€æŸ¥æ ‡é¢˜å±‚çº§ç»“æ„ (15åˆ†)
                    h1_count = content.count('<h1')
                    h2_count = content.count('<h2')
                    h3_count = content.count('<h3')
                    
                    if h1_count == 1 and h2_count > 0:
                        accessibility_score += 15
                        checks.append("âœ… æ ‡é¢˜å±‚çº§ç»“æ„æ­£ç¡®")
                    elif h1_count == 1:
                        accessibility_score += 10
                        checks.append("âš ï¸ æœ‰h1ä½†ç¼ºå°‘h2")
                    else:
                        accessibility_score += 0
                        checks.append(f"âŒ h1æ ‡ç­¾æ•°é‡å¼‚å¸¸: {h1_count}")
                    
                    # 4. æ£€æŸ¥è¡¨å•å¯è®¿é—®æ€§ (20åˆ†)
                    if '<form' in content:
                        label_count = content.count('<label')
                        input_count = content.count('<input')
                        required_count = content.count('required')
                        aria_required_count = content.count('aria-required')
                        
                        form_score = 0
                        if label_count >= input_count * 0.9:
                            form_score += 10
                            checks.append("âœ… è¡¨å•æ ‡ç­¾å®Œæ•´")
                        else:
                            checks.append("âŒ è¡¨å•ç¼ºå°‘æ ‡ç­¾")
                        
                        if required_count > 0 or aria_required_count > 0:
                            form_score += 5
                            checks.append("âœ… å¿…å¡«å­—æ®µæ ‡è¯†")
                        
                        if 'aria-describedby' in content:
                            form_score += 5
                            checks.append("âœ… è¡¨å•å¸®åŠ©æ–‡æœ¬")
                        
                        accessibility_score += form_score
                    else:
                        accessibility_score += 20
                        checks.append("âœ… æ— è¡¨å•æˆ–å·²å¤„ç†")
                    
                    # 5. æ£€æŸ¥é”®ç›˜å¯¼èˆªæ”¯æŒ (10åˆ†)
                    keyboard_support = [
                        'tabindex=', 'accesskey=', 'onkeydown=', 'onkeyup=',
                        'focus()', 'blur()', ':focus'
                    ]
                    keyboard_count = sum(1 for support in keyboard_support if support in content)
                    
                    if keyboard_count >= 3:
                        accessibility_score += 10
                        checks.append("âœ… é”®ç›˜å¯¼èˆªæ”¯æŒ")
                    elif keyboard_count >= 1:
                        accessibility_score += 5
                        checks.append("âš ï¸ åŸºç¡€é”®ç›˜å¯¼èˆª")
                    else:
                        checks.append("âŒ ç¼ºå°‘é”®ç›˜å¯¼èˆªæ”¯æŒ")
                    
                    # 6. æ£€æŸ¥è·³è½¬é“¾æ¥å’Œæ— éšœç¢åŠŸèƒ½ (10åˆ†)
                    accessibility_features = [
                        'skip-link', 'sr-only', 'screen-reader',
                        'prefers-reduced-motion', 'prefers-contrast'
                    ]
                    feature_count = sum(1 for feature in accessibility_features if feature in content)
                    
                    if feature_count >= 2:
                        accessibility_score += 10
                        checks.append("âœ… æ— éšœç¢åŠŸèƒ½å®Œæ•´")
                    elif feature_count >= 1:
                        accessibility_score += 5
                        checks.append("âš ï¸ åŸºç¡€æ— éšœç¢åŠŸèƒ½")
                    else:
                        checks.append("âŒ ç¼ºå°‘æ— éšœç¢åŠŸèƒ½")
                    
                    # ç”Ÿæˆè¯¦ç»†å»ºè®®
                    recommendations = []
                    if accessibility_score < 90:
                        if alt_count < img_count:
                            recommendations.append("ä¸ºæ‰€æœ‰å›¾ç‰‡æ·»åŠ æè¿°æ€§altå±æ€§")
                        if semantic_count < 4:
                            recommendations.append("ä½¿ç”¨æ›´å¤šè¯­ä¹‰åŒ–HTML5æ ‡ç­¾")
                        if aria_count < 2:
                            recommendations.append("æ·»åŠ ARIAæ ‡ç­¾æå‡å¯è®¿é—®æ€§")
                        if h1_count != 1:
                            recommendations.append("ç¡®ä¿æ¯é¡µåªæœ‰ä¸€ä¸ªh1æ ‡ç­¾")
                        if keyboard_count < 3:
                            recommendations.append("æ·»åŠ å®Œæ•´çš„é”®ç›˜å¯¼èˆªæ”¯æŒ")
                        if feature_count < 2:
                            recommendations.append("å®æ–½è·³è½¬é“¾æ¥å’Œå±å¹•é˜…è¯»å™¨æ”¯æŒ")
                        
                        recommendations.extend([
                            "ç¡®ä¿é¢œè‰²å¯¹æ¯”åº¦ç¬¦åˆWCAG 2.1 AAæ ‡å‡†",
                            "æ·»åŠ ç„¦ç‚¹æŒ‡ç¤ºå™¨æ ·å¼",
                            "æ”¯æŒç”¨æˆ·åå¥½è®¾ç½®ï¼ˆå‡å°‘åŠ¨ç”»ã€é«˜å¯¹æ¯”åº¦ï¼‰",
                            "æä¾›å¤šç§æ–¹å¼è®¿é—®ç›¸åŒä¿¡æ¯"
                        ])
                    
                    page_name = page if page != "/" else "é¦–é¡µ"
                    self.add_test_result(
                        f"å¯è®¿é—®æ€§æµ‹è¯•: {page_name}",
                        "accessibility",
                        accessibility_score,
                        f"å¯è®¿é—®æ€§è¯„åˆ†: {accessibility_score}/100",
                        {
                            "page": page,
                            "checks": checks,
                            "img_count": img_count,
                            "alt_count": alt_count,
                            "semantic_count": semantic_count,
                            "aria_count": aria_count,
                            "keyboard_support_count": keyboard_count
                        },
                        recommendations
                    )
                    
            except Exception as e:
                self.add_test_result(
                    f"å¯è®¿é—®æ€§æµ‹è¯•: {page}",
                    "accessibility",
                    0,
                    f"æµ‹è¯•å¤±è´¥: {str(e)}",
                    {"error": str(e)},
                    ["ä¿®å¤é¡µé¢è®¿é—®é—®é¢˜", "æ£€æŸ¥æœåŠ¡å™¨è¿æ¥"]
                )   
 
    async def test_usability_heuristics(self) -> None:
        """æµ‹è¯•å¯ç”¨æ€§å¯å‘å¼åŸåˆ™"""
        # æ¨¡æ‹Ÿå¯ç”¨æ€§æµ‹è¯•
        usability_tests = [
            {
                "name": "å¯¼èˆªä¸€è‡´æ€§",
                "category": "navigation",
                "score": 85,
                "description": "å¯¼èˆªèœå•åœ¨å„é¡µé¢ä¿æŒä¸€è‡´",
                "recommendations": ["ç»Ÿä¸€å¯¼èˆªæ ·å¼", "æ·»åŠ é¢åŒ…å±‘å¯¼èˆª"]
            },
            {
                "name": "é”™è¯¯å¤„ç†",
                "category": "error_handling", 
                "score": 78,
                "description": "é”™è¯¯ä¿¡æ¯æ¸…æ™°ä½†å¯ä»¥æ›´å‹å¥½",
                "recommendations": ["ä½¿ç”¨æ›´å‹å¥½çš„é”™è¯¯æç¤º", "æä¾›è§£å†³æ–¹æ¡ˆå»ºè®®"]
            },
            {
                "name": "åé¦ˆæœºåˆ¶",
                "category": "feedback",
                "score": 82,
                "description": "æ“ä½œåé¦ˆåŠæ—¶ä½†ä¸å¤Ÿæ˜æ˜¾",
                "recommendations": ["å¢å¼ºè§†è§‰åé¦ˆ", "æ·»åŠ æ“ä½œç¡®è®¤æç¤º"]
            },
            {
                "name": "ä¿¡æ¯æ¶æ„",
                "category": "information_architecture",
                "score": 88,
                "description": "ä¿¡æ¯ç»„ç»‡åˆç†ï¼Œå±‚æ¬¡æ¸…æ™°",
                "recommendations": ["ä¼˜åŒ–ä¿¡æ¯åˆ†ç»„", "ç®€åŒ–å¤æ‚æµç¨‹"]
            },
            {
                "name": "è§†è§‰è®¾è®¡",
                "category": "visual_design",
                "score": 75,
                "description": "è®¾è®¡é£æ ¼ç»Ÿä¸€ä½†ç¼ºä¹ç°ä»£æ„Ÿ",
                "recommendations": ["æ›´æ–°è§†è§‰é£æ ¼", "ä¼˜åŒ–è‰²å½©æ­é…", "æ”¹è¿›å›¾æ ‡è®¾è®¡"]
            }
        ]
        
        for test in usability_tests:
            self.add_test_result(
                f"å¯ç”¨æ€§æµ‹è¯•: {test['name']}",
                "usability",
                test["score"],
                test["description"],
                {"category": test["category"]},
                test["recommendations"]
            )
    
    async def test_form_usability(self) -> None:
        """æµ‹è¯•è¡¨å•å¯ç”¨æ€§"""
        # æ¨¡æ‹Ÿè¡¨å•æµ‹è¯•
        form_tests = [
            {
                "form": "ç™»å½•è¡¨å•",
                "score": 85,
                "issues": ["ç¼ºå°‘å¯†ç æ˜¾ç¤ºåˆ‡æ¢", "è®°ä½æˆ‘åŠŸèƒ½ä¸æ˜æ˜¾"],
                "strengths": ["å­—æ®µéªŒè¯åŠæ—¶", "é”™è¯¯æç¤ºæ¸…æ™°"]
            },
            {
                "form": "æ³¨å†Œè¡¨å•", 
                "score": 78,
                "issues": ["å¯†ç å¼ºåº¦æç¤ºä¸å¤Ÿè¯¦ç»†", "é‚®ç®±éªŒè¯åé¦ˆå»¶è¿Ÿ"],
                "strengths": ["å­—æ®µæ ‡ç­¾æ¸…æ™°", "å¿…å¡«é¡¹æ ‡è¯†æ˜ç¡®"]
            },
            {
                "form": "æ¡ˆä»¶åˆ›å»ºè¡¨å•",
                "score": 82,
                "issues": ["æ–‡ä»¶ä¸Šä¼ è¿›åº¦ä¸æ˜æ˜¾", "ä¿å­˜è‰ç¨¿åŠŸèƒ½ç¼ºå¤±"],
                "strengths": ["åˆ†æ­¥éª¤å¼•å¯¼", "å­—æ®µå¸®åŠ©æç¤ºå®Œå–„"]
            }
        ]
        
        for test in form_tests:
            recommendations = []
            recommendations.extend([f"ä¿®å¤: {issue}" for issue in test["issues"]])
            recommendations.extend([f"ä¿æŒ: {strength}" for strength in test["strengths"]])
            
            self.add_test_result(
                f"è¡¨å•å¯ç”¨æ€§: {test['form']}",
                "forms",
                test["score"],
                f"è¡¨å•ä½“éªŒè¯„åˆ†: {test['score']}/100",
                {
                    "issues": test["issues"],
                    "strengths": test["strengths"]
                },
                recommendations
            )
    
    async def test_loading_states(self) -> None:
        """æµ‹è¯•åŠ è½½çŠ¶æ€å’Œåé¦ˆ"""
        loading_scenarios = [
            {
                "scenario": "é¡µé¢åˆå§‹åŠ è½½",
                "score": 70,
                "has_loading": True,
                "loading_type": "spinner",
                "feedback_quality": "basic"
            },
            {
                "scenario": "æ•°æ®æäº¤",
                "score": 65,
                "has_loading": False,
                "loading_type": "none",
                "feedback_quality": "poor"
            },
            {
                "scenario": "æ–‡ä»¶ä¸Šä¼ ",
                "score": 80,
                "has_loading": True,
                "loading_type": "progress_bar",
                "feedback_quality": "good"
            }
        ]
        
        for scenario in loading_scenarios:
            recommendations = []
            
            if not scenario["has_loading"]:
                recommendations.append("æ·»åŠ åŠ è½½æŒ‡ç¤ºå™¨")
            
            if scenario["feedback_quality"] == "poor":
                recommendations.extend([
                    "æ·»åŠ æ“ä½œåé¦ˆ",
                    "æ˜¾ç¤ºå¤„ç†è¿›åº¦",
                    "æä¾›å–æ¶ˆé€‰é¡¹"
                ])
            elif scenario["feedback_quality"] == "basic":
                recommendations.extend([
                    "æ”¹è¿›åŠ è½½åŠ¨ç”»",
                    "æ·»åŠ è¿›åº¦ç™¾åˆ†æ¯”",
                    "ä¼˜åŒ–åŠ è½½æ–‡æ¡ˆ"
                ])
            
            self.add_test_result(
                f"åŠ è½½çŠ¶æ€: {scenario['scenario']}",
                "loading",
                scenario["score"],
                f"åŠ è½½åé¦ˆè´¨é‡: {scenario['feedback_quality']}",
                {
                    "has_loading": scenario["has_loading"],
                    "loading_type": scenario["loading_type"],
                    "feedback_quality": scenario["feedback_quality"]
                },
                recommendations
            )
    
    async def test_search_functionality(self) -> None:
        """æµ‹è¯•æœç´¢åŠŸèƒ½å¯ç”¨æ€§"""
        search_tests = [
            {
                "feature": "å…¨å±€æœç´¢",
                "score": 75,
                "has_autocomplete": True,
                "has_filters": False,
                "response_time": "fast",
                "result_relevance": "good"
            },
            {
                "feature": "æ¡ˆä»¶æœç´¢",
                "score": 82,
                "has_autocomplete": True,
                "has_filters": True,
                "response_time": "medium",
                "result_relevance": "excellent"
            },
            {
                "feature": "ç”¨æˆ·æœç´¢",
                "score": 68,
                "has_autocomplete": False,
                "has_filters": False,
                "response_time": "slow",
                "result_relevance": "fair"
            }
        ]
        
        for test in search_tests:
            recommendations = []
            
            if not test["has_autocomplete"]:
                recommendations.append("æ·»åŠ æœç´¢è‡ªåŠ¨å®Œæˆ")
            
            if not test["has_filters"]:
                recommendations.append("æ·»åŠ æœç´¢è¿‡æ»¤å™¨")
            
            if test["response_time"] == "slow":
                recommendations.append("ä¼˜åŒ–æœç´¢æ€§èƒ½")
            
            if test["result_relevance"] in ["fair", "poor"]:
                recommendations.extend([
                    "æ”¹è¿›æœç´¢ç®—æ³•",
                    "ä¼˜åŒ–ç»“æœæ’åº",
                    "æ·»åŠ æœç´¢å»ºè®®"
                ])
            
            self.add_test_result(
                f"æœç´¢åŠŸèƒ½: {test['feature']}",
                "search",
                test["score"],
                f"æœç´¢ä½“éªŒè¯„åˆ†: {test['score']}/100",
                {
                    "has_autocomplete": test["has_autocomplete"],
                    "has_filters": test["has_filters"],
                    "response_time": test["response_time"],
                    "result_relevance": test["result_relevance"]
                },
                recommendations
            )
    
    async def run_ux_test_suite(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„ç”¨æˆ·ä½“éªŒæµ‹è¯•å¥—ä»¶"""
        logger.info("Starting user experience test suite...")
        
        test_report = {
            "test_suite": "User Experience Test Suite",
            "start_time": datetime.now().isoformat(),
            "base_url": self.base_url,
            "test_results": []
        }
        
        # è¿è¡Œæ‰€æœ‰UXæµ‹è¯•
        test_functions = [
            ("é¡µé¢åŠ è½½æ€§èƒ½æµ‹è¯•", self.test_page_load_performance),
            ("ç§»åŠ¨ç«¯å“åº”å¼æµ‹è¯•", self.test_mobile_responsiveness),
            ("å¯è®¿é—®æ€§æµ‹è¯•", self.test_accessibility),
            ("å¯ç”¨æ€§å¯å‘å¼æµ‹è¯•", self.test_usability_heuristics),
            ("è¡¨å•å¯ç”¨æ€§æµ‹è¯•", self.test_form_usability),
            ("åŠ è½½çŠ¶æ€æµ‹è¯•", self.test_loading_states),
            ("æœç´¢åŠŸèƒ½æµ‹è¯•", self.test_search_functionality)
        ]
        
        print(f"\n{'='*60}")
        print("RUNNING USER EXPERIENCE TESTS")
        print(f"{'='*60}")
        
        for test_description, test_function in test_functions:
            try:
                print(f"\n--- {test_description} ---")
                await test_function()
                await asyncio.sleep(0.5)  # æµ‹è¯•é—´éš”
            except Exception as e:
                logger.error(f"Test {test_description} failed: {str(e)}")
                self.add_test_result(
                    test_description, "error", 0,
                    f"æµ‹è¯•å¤±è´¥: {str(e)}",
                    {"error": str(e)},
                    ["ä¿®å¤æµ‹è¯•é”™è¯¯"]
                )
        
        test_report["test_results"] = [result.to_dict() for result in self.test_results]
        test_report["end_time"] = datetime.now().isoformat()
        
        # ç”Ÿæˆæµ‹è¯•æ‘˜è¦å’Œå»ºè®®
        test_report["summary"] = self.generate_summary()
        test_report["optimization_plan"] = self.generate_optimization_plan()
        
        return test_report
    
    def generate_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æ‘˜è¦"""
        if not self.test_results:
            return {"error": "No test results available"}
        
        # è®¡ç®—æ€»ä½“åˆ†æ•°
        total_score = sum(result.score for result in self.test_results)
        avg_score = total_score / len(self.test_results)
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        categories = {}
        for result in self.test_results:
            category = result.test_category
            if category not in categories:
                categories[category] = {"scores": [], "count": 0}
            
            categories[category]["scores"].append(result.score)
            categories[category]["count"] += 1
        
        # è®¡ç®—å„ç±»åˆ«å¹³å‡åˆ†
        for category, data in categories.items():
            data["average_score"] = sum(data["scores"]) / len(data["scores"])
            data["status"] = self._get_status_from_score(data["average_score"])
        
        # ç»Ÿè®¡å„çŠ¶æ€æ•°é‡
        status_counts = {"excellent": 0, "good": 0, "fair": 0, "poor": 0}
        for result in self.test_results:
            status_counts[result.status] += 1
        
        # æ•´ä½“è¯„çº§
        if avg_score >= 90:
            overall_rating = "ä¼˜ç§€"
        elif avg_score >= 80:
            overall_rating = "è‰¯å¥½"
        elif avg_score >= 70:
            overall_rating = "ä¸€èˆ¬"
        else:
            overall_rating = "éœ€è¦æ”¹è¿›"
        
        return {
            "overall_score": round(avg_score, 1),
            "overall_rating": overall_rating,
            "total_tests": len(self.test_results),
            "categories": categories,
            "status_distribution": status_counts,
            "top_issues": self._get_top_issues(),
            "strengths": self._get_strengths()
        }
    
    def _get_status_from_score(self, score: float) -> str:
        """æ ¹æ®åˆ†æ•°è·å–çŠ¶æ€"""
        if score >= 90:
            return "excellent"
        elif score >= 75:
            return "good"
        elif score >= 60:
            return "fair"
        else:
            return "poor"
    
    def _get_top_issues(self) -> List[Dict[str, Any]]:
        """è·å–ä¸»è¦é—®é¢˜"""
        poor_results = [r for r in self.test_results if r.score < 70]
        poor_results.sort(key=lambda x: x.score)
        
        return [
            {
                "test_name": result.test_name,
                "score": result.score,
                "category": result.test_category,
                "message": result.message,
                "recommendations": result.recommendations[:3]  # å‰3ä¸ªå»ºè®®
            }
            for result in poor_results[:5]  # å‰5ä¸ªé—®é¢˜
        ]
    
    def _get_strengths(self) -> List[Dict[str, Any]]:
        """è·å–ä¼˜åŠ¿é¡¹ç›®"""
        good_results = [r for r in self.test_results if r.score >= 85]
        good_results.sort(key=lambda x: x.score, reverse=True)
        
        return [
            {
                "test_name": result.test_name,
                "score": result.score,
                "category": result.test_category,
                "message": result.message
            }
            for result in good_results[:5]  # å‰5ä¸ªä¼˜åŠ¿
        ]
    
    def generate_optimization_plan(self) -> Dict[str, Any]:
        """ç”Ÿæˆä¼˜åŒ–è®¡åˆ’"""
        # æ”¶é›†æ‰€æœ‰å»ºè®®
        all_recommendations = []
        for result in self.test_results:
            for rec in result.recommendations:
                all_recommendations.append({
                    "recommendation": rec,
                    "category": result.test_category,
                    "priority": "high" if result.score < 60 else "medium" if result.score < 80 else "low",
                    "test_name": result.test_name
                })
        
        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
        priority_groups = {"high": [], "medium": [], "low": []}
        for rec in all_recommendations:
            priority_groups[rec["priority"]].append(rec)
        
        # æŒ‰ç±»åˆ«åˆ†ç»„å»ºè®®
        category_recommendations = {}
        for rec in all_recommendations:
            category = rec["category"]
            if category not in category_recommendations:
                category_recommendations[category] = []
            category_recommendations[category].append(rec["recommendation"])
        
        # å»é‡
        for category in category_recommendations:
            category_recommendations[category] = list(set(category_recommendations[category]))
        
        return {
            "priority_recommendations": {
                "high_priority": [rec["recommendation"] for rec in priority_groups["high"]],
                "medium_priority": [rec["recommendation"] for rec in priority_groups["medium"]],
                "low_priority": [rec["recommendation"] for rec in priority_groups["low"]]
            },
            "category_recommendations": category_recommendations,
            "implementation_phases": {
                "phase_1_critical": "ä¿®å¤è¯„åˆ†ä½äº60åˆ†çš„é—®é¢˜",
                "phase_2_improvement": "ä¼˜åŒ–è¯„åˆ†60-80åˆ†çš„é¡¹ç›®", 
                "phase_3_enhancement": "æå‡è¯„åˆ†80åˆ†ä»¥ä¸Šçš„é¡¹ç›®"
            }
        }
    
    def save_report(self, test_report: Dict[str, Any], filename: str = "ux_test_report.json"):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        report_path = Path(filename)
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(test_report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"UX test report saved to: {report_path.absolute()}")
        self.print_summary(test_report)
    
    def print_summary(self, test_report: Dict[str, Any]):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        summary = test_report.get("summary", {})
        optimization = test_report.get("optimization_plan", {})
        
        print(f"\n{'='*70}")
        print("USER EXPERIENCE TEST REPORT SUMMARY")
        print(f"{'='*70}")
        
        # æ•´ä½“è¯„åˆ†
        overall_score = summary.get("overall_score", 0)
        overall_rating = summary.get("overall_rating", "æœªçŸ¥")
        
        rating_icon = {
            "ä¼˜ç§€": "ğŸ¯",
            "è‰¯å¥½": "âœ…", 
            "ä¸€èˆ¬": "âš ï¸",
            "éœ€è¦æ”¹è¿›": "âŒ"
        }.get(overall_rating, "â“")
        
        print(f"æ•´ä½“è¯„åˆ†: {rating_icon} {overall_score}/100 ({overall_rating})")
        print(f"æµ‹è¯•é¡¹ç›®: {summary.get('total_tests', 0)}")
        
        # çŠ¶æ€åˆ†å¸ƒ
        status_dist = summary.get("status_distribution", {})
        print(f"è¯„åˆ†åˆ†å¸ƒ: ä¼˜ç§€({status_dist.get('excellent', 0)}) è‰¯å¥½({status_dist.get('good', 0)}) ä¸€èˆ¬({status_dist.get('fair', 0)}) å·®({status_dist.get('poor', 0)})")
        
        # æŒ‰ç±»åˆ«æ˜¾ç¤ºç»“æœ
        categories = summary.get("categories", {})
        if categories:
            print(f"\næŒ‰ç±»åˆ«è¯„åˆ†:")
            print("-" * 50)
            for category, data in categories.items():
                score = data["average_score"]
                status = data["status"]
                status_icon = {"excellent": "ğŸ¯", "good": "âœ…", "fair": "âš ï¸", "poor": "âŒ"}[status]
                category_name = {
                    "performance": "æ€§èƒ½",
                    "mobile": "ç§»åŠ¨ç«¯",
                    "accessibility": "å¯è®¿é—®æ€§",
                    "usability": "å¯ç”¨æ€§",
                    "forms": "è¡¨å•",
                    "loading": "åŠ è½½çŠ¶æ€",
                    "search": "æœç´¢åŠŸèƒ½"
                }.get(category, category)
                
                print(f"{status_icon} {category_name}: {score:.1f}/100 ({data['count']}é¡¹æµ‹è¯•)")
        
        # ä¸»è¦é—®é¢˜
        top_issues = summary.get("top_issues", [])
        if top_issues:
            print(f"\nä¸»è¦é—®é¢˜:")
            print("-" * 50)
            for issue in top_issues:
                print(f"âŒ {issue['test_name']}: {issue['score']:.1f}/100")
                print(f"   {issue['message']}")
                if issue['recommendations']:
                    print(f"   å»ºè®®: {issue['recommendations'][0]}")
        
        # ä¼˜åŠ¿é¡¹ç›®
        strengths = summary.get("strengths", [])
        if strengths:
            print(f"\nä¼˜åŠ¿é¡¹ç›®:")
            print("-" * 50)
            for strength in strengths:
                print(f"âœ… {strength['test_name']}: {strength['score']:.1f}/100")
        
        # ä¼˜åŒ–å»ºè®®
        priority_recs = optimization.get("priority_recommendations", {})
        high_priority = priority_recs.get("high_priority", [])
        
        if high_priority:
            print(f"\né«˜ä¼˜å…ˆçº§ä¼˜åŒ–å»ºè®®:")
            print("-" * 50)
            for i, rec in enumerate(high_priority[:5], 1):
                print(f"{i}. {rec}")
        
        print(f"{'='*70}")

async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ç”¨æˆ·ä½“éªŒæµ‹è¯•å·¥å…·")
    parser.add_argument("--url", default="http://localhost:8000", help="ç½‘ç«™åŸºç¡€URL")
    parser.add_argument("--output", default="ux_test_report.json", help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶")
    
    args = parser.parse_args()
    
    try:
        async with UserExperienceTester(args.url) as tester:
            test_report = await tester.run_ux_test_suite()
            tester.save_report(test_report, args.output)
            
            # æ ¹æ®æµ‹è¯•ç»“æœè®¾ç½®é€€å‡ºç 
            overall_score = test_report.get("summary", {}).get("overall_score", 0)
            if overall_score >= 75:
                return 0
            else:
                return 1
                
    except KeyboardInterrupt:
        logger.info("UX test interrupted by user")
        return 1
    except Exception as e:
        logger.error(f"UX test failed: {str(e)}")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)