#!/usr/bin/env python3
"""
ELK Stackæ—¥å¿—èšåˆç³»ç»Ÿéƒ¨ç½²è„šæœ¬
è‡ªåŠ¨åŒ–éƒ¨ç½²Elasticsearchã€Logstashã€Kibana
"""
import asyncio
import json
import os
import sys
import subprocess
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.elk_service import elk_service, setup_elk_logging

def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    print("=" * 60)
    print("ğŸ“Š LAWSKER ELK STACKæ—¥å¿—èšåˆç³»ç»Ÿéƒ¨ç½²")
    print("=" * 60)
    print(f"ğŸ“… éƒ¨ç½²æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

def print_section_header(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*20} {title} {'='*20}")

def check_prerequisites():
    """æ£€æŸ¥å‰ç½®æ¡ä»¶"""
    print("ğŸ” æ£€æŸ¥å‰ç½®æ¡ä»¶...")
    
    prerequisites = {
        "docker": "docker --version",
        "docker-compose": "docker-compose --version",
    }
    
    missing_tools = []
    
    for tool, command in prerequisites.items():
        try:
            result = subprocess.run(
                command.split(),
                capture_output=True,
                text=True,
                timeout=10
            )
            if result.returncode == 0:
                print(f"  âœ… {tool}: å·²å®‰è£…")
            else:
                print(f"  âŒ {tool}: æœªæ‰¾åˆ°")
                missing_tools.append(tool)
        except (subprocess.TimeoutExpired, FileNotFoundError):
            print(f"  âŒ {tool}: æœªæ‰¾åˆ°")
            missing_tools.append(tool)
    
    if missing_tools:
        print(f"\nâš ï¸  ç¼ºå°‘å·¥å…·: {', '.join(missing_tools)}")
        print("è¯·å®‰è£…ç¼ºå°‘çš„å·¥å…·åé‡æ–°è¿è¡Œ")
        return False
    
    return True

def create_elk_docker_compose():
    """åˆ›å»ºELK Stack Docker Composeé…ç½®"""
    print("ğŸ³ åˆ›å»ºELK Stack Docker Composeé…ç½®...")
    
    docker_compose_content = """
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: lawsker-elasticsearch
    restart: unless-stopped
    environment:
      - node.name=elasticsearch
      - cluster.name=lawsker-elk-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
      - ./config/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - elk-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: lawsker-logstash
    restart: unless-stopped
    environment:
      - "LS_JAVA_OPTS=-Xmx512m -Xms512m"
    volumes:
      - ./config/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./config/logstash/pipelines.yml:/usr/share/logstash/config/pipelines.yml
      - ./config/logstash/pipeline:/usr/share/logstash/pipeline
      - ./logs:/usr/share/logstash/logs
    ports:
      - "5044:5044"
      - "9600:9600"
      - "5000:5000/tcp"
      - "5000:5000/udp"
    networks:
      - elk-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9600/_node/stats || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: lawsker-kibana
    restart: unless-stopped
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - SERVER_NAME=kibana
      - SERVER_HOST=0.0.0.0
    volumes:
      - ./config/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml
    ports:
      - "5601:5601"
    networks:
      - elk-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: lawsker-filebeat
    restart: unless-stopped
    user: root
    volumes:
      - ./config/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - ./logs:/var/log/lawsker:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data:/usr/share/filebeat/data
    networks:
      - elk-network
    depends_on:
      logstash:
        condition: service_healthy
    command: filebeat -e -strict.perms=false

volumes:
  elasticsearch-data:
  filebeat-data:

networks:
  elk-network:
    driver: bridge
"""
    
    with open("docker-compose.elk.yml", "w", encoding="utf-8") as f:
        f.write(docker_compose_content)
    
    print("  âœ… ELK Stack Docker Composeé…ç½®å·²åˆ›å»º: docker-compose.elk.yml")
    return True

def create_elasticsearch_config():
    """åˆ›å»ºElasticsearché…ç½®"""
    print("ğŸ” åˆ›å»ºElasticsearché…ç½®...")
    
    config_dir = Path("config/elasticsearch")
    config_dir.mkdir(parents=True, exist_ok=True)
    
    elasticsearch_yml = """
cluster.name: "lawsker-elk-cluster"
node.name: "elasticsearch"
path.data: /usr/share/elasticsearch/data
path.logs: /usr/share/elasticsearch/logs
network.host: 0.0.0.0
http.port: 9200
discovery.type: single-node
bootstrap.memory_lock: true

# Security settings
xpack.security.enabled: false
xpack.security.enrollment.enabled: false

# Index settings
action.auto_create_index: true
action.destructive_requires_name: true

# Monitoring
xpack.monitoring.collection.enabled: true

# Machine learning
xpack.ml.enabled: false

# Watcher
xpack.watcher.enabled: false
"""
    
    with open(config_dir / "elasticsearch.yml", "w", encoding="utf-8") as f:
        f.write(elasticsearch_yml)
    
    print(f"  âœ… Elasticsearché…ç½®å·²åˆ›å»º: {config_dir / 'elasticsearch.yml'}")
    return True

def create_logstash_config():
    """åˆ›å»ºLogstashé…ç½®"""
    print("ğŸ“Š åˆ›å»ºLogstashé…ç½®...")
    
    config_dir = Path("config/logstash")
    config_dir.mkdir(parents=True, exist_ok=True)
    
    # Logstashä¸»é…ç½®
    logstash_yml = """
http.host: "0.0.0.0"
path.config: /usr/share/logstash/pipeline
path.logs: /usr/share/logstash/logs
xpack.monitoring.enabled: false
"""
    
    with open(config_dir / "logstash.yml", "w", encoding="utf-8") as f:
        f.write(logstash_yml)
    
    # Pipelineé…ç½®
    pipelines_yml = """
- pipeline.id: lawsker-logs
  path.config: "/usr/share/logstash/pipeline/lawsker.conf"
"""
    
    with open(config_dir / "pipelines.yml", "w", encoding="utf-8") as f:
        f.write(pipelines_yml)
    
    # Pipelineç›®å½•
    pipeline_dir = config_dir / "pipeline"
    pipeline_dir.mkdir(exist_ok=True)
    
    # Lawskeræ—¥å¿—å¤„ç†é…ç½®
    lawsker_conf = """
input {
  beats {
    port => 5044
  }
  
  tcp {
    port => 5000
    codec => json_lines
  }
  
  udp {
    port => 5000
    codec => json_lines
  }
}

filter {
  # å¤„ç†åº”ç”¨æ—¥å¿—
  if [fields][log_type] == "application" {
    mutate {
      add_field => { "log_category" => "application" }
    }
    
    # è§£ææ—¥å¿—çº§åˆ«
    if [message] =~ /ERROR/ {
      mutate { add_field => { "log_level" => "ERROR" } }
    } else if [message] =~ /WARN/ {
      mutate { add_field => { "log_level" => "WARN" } }
    } else if [message] =~ /INFO/ {
      mutate { add_field => { "log_level" => "INFO" } }
    } else if [message] =~ /DEBUG/ {
      mutate { add_field => { "log_level" => "DEBUG" } }
    }
    
    # æå–å¼‚å¸¸ä¿¡æ¯
    if [message] =~ /Exception|Error|Traceback/ {
      mutate { add_field => { "has_exception" => "true" } }
    }
  }
  
  # å¤„ç†è®¿é—®æ—¥å¿—
  if [fields][log_type] == "access" {
    mutate {
      add_field => { "log_category" => "access" }
    }
    
    # è§£æNginxè®¿é—®æ—¥å¿—æ ¼å¼
    grok {
      match => { 
        "message" => "%{IPORHOST:remote_addr} - %{DATA:remote_user} \\[%{HTTPDATE:time_local}\\] \"%{WORD:method} %{DATA:request} HTTP/%{NUMBER:http_version}\" %{INT:status} %{INT:body_bytes_sent} \"%{DATA:http_referer}\" \"%{DATA:http_user_agent}\" %{NUMBER:request_time}" 
      }
    }
    
    # è½¬æ¢æ•°æ®ç±»å‹
    mutate {
      convert => { 
        "status" => "integer"
        "body_bytes_sent" => "integer"
        "request_time" => "float"
      }
    }
    
    # æ·»åŠ çŠ¶æ€ç åˆ†ç±»
    if [status] >= 500 {
      mutate { add_field => { "status_category" => "5xx" } }
    } else if [status] >= 400 {
      mutate { add_field => { "status_category" => "4xx" } }
    } else if [status] >= 300 {
      mutate { add_field => { "status_category" => "3xx" } }
    } else if [status] >= 200 {
      mutate { add_field => { "status_category" => "2xx" } }
    }
  }
  
  # å¤„ç†å®‰å…¨æ—¥å¿—
  if [fields][log_type] == "security" {
    mutate {
      add_field => { "log_category" => "security" }
    }
    
    # æ£€æµ‹å®‰å…¨äº‹ä»¶
    if [message] =~ /login.*failed|authentication.*failed|unauthorized|forbidden/ {
      mutate { add_field => { "security_event" => "auth_failure" } }
    } else if [message] =~ /login.*success|authentication.*success/ {
      mutate { add_field => { "security_event" => "auth_success" } }
    } else if [message] =~ /sql.*injection|xss|csrf/ {
      mutate { add_field => { "security_event" => "attack_attempt" } }
    }
  }
  
  # æ·»åŠ é€šç”¨å­—æ®µ
  mutate {
    add_field => { 
      "environment" => "${ENVIRONMENT:development}"
      "service" => "lawsker"
    }
  }
  
  # è§£ææ—¶é—´æˆ³
  date {
    match => [ "@timestamp", "ISO8601" ]
  }
}

output {
  # æ ¹æ®æ—¥å¿—ç±»å‹è¾“å‡ºåˆ°ä¸åŒç´¢å¼•
  if [log_category] == "application" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "lawsker-app-logs-%{+YYYY.MM.dd}"
      template_name => "lawsker-app-logs"
    }
  } else if [log_category] == "access" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "lawsker-access-logs-%{+YYYY.MM.dd}"
      template_name => "lawsker-access-logs"
    }
  } else if [log_category] == "security" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "lawsker-security-logs-%{+YYYY.MM.dd}"
      template_name => "lawsker-security-logs"
    }
  } else {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "lawsker-general-logs-%{+YYYY.MM.dd}"
    }
  }
  
  # è°ƒè¯•è¾“å‡ºï¼ˆå¯é€‰ï¼‰
  # stdout { codec => rubydebug }
}
"""
    
    with open(pipeline_dir / "lawsker.conf", "w", encoding="utf-8") as f:
        f.write(lawsker_conf)
    
    print(f"  âœ… Logstashé…ç½®å·²åˆ›å»º: {config_dir}")
    return True

def create_kibana_config():
    """åˆ›å»ºKibanaé…ç½®"""
    print("ğŸ“Š åˆ›å»ºKibanaé…ç½®...")
    
    config_dir = Path("config/kibana")
    config_dir.mkdir(parents=True, exist_ok=True)
    
    kibana_yml = """
server.name: kibana
server.host: 0.0.0.0
server.port: 5601
elasticsearch.hosts: ["http://elasticsearch:9200"]

# Monitoring
monitoring.ui.container.elasticsearch.enabled: true

# Security
xpack.security.enabled: false
xpack.encryptedSavedObjects.encryptionKey: "lawsker_kibana_encryption_key_32_chars"

# Logging
logging.appenders.file.type: file
logging.appenders.file.fileName: /usr/share/kibana/logs/kibana.log
logging.appenders.file.layout.type: json
logging.root.appenders: [default, file]
logging.root.level: info

# Telemetry
telemetry.enabled: false
telemetry.optIn: false

# Maps
map.includeElasticMapsService: false
"""
    
    with open(config_dir / "kibana.yml", "w", encoding="utf-8") as f:
        f.write(kibana_yml)
    
    print(f"  âœ… Kibanaé…ç½®å·²åˆ›å»º: {config_dir / 'kibana.yml'}")
    return True

def create_filebeat_config():
    """åˆ›å»ºFilebeaté…ç½®"""
    print("ğŸ“„ åˆ›å»ºFilebeaté…ç½®...")
    
    config_dir = Path("config/filebeat")
    config_dir.mkdir(parents=True, exist_ok=True)
    
    filebeat_yml = """
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/lawsker/app/*.log
  fields:
    log_type: application
    service: lawsker-api
  fields_under_root: false
  multiline.pattern: '^\\d{4}-\\d{2}-\\d{2}'
  multiline.negate: true
  multiline.match: after

- type: log
  enabled: true
  paths:
    - /var/log/lawsker/access/*.log
  fields:
    log_type: access
    service: lawsker-nginx
  fields_under_root: false

- type: log
  enabled: true
  paths:
    - /var/log/lawsker/security/*.log
  fields:
    log_type: security
    service: lawsker-security
  fields_under_root: false

- type: container
  enabled: true
  paths:
    - '/var/lib/docker/containers/*/*.log'
  processors:
    - add_docker_metadata:
        host: "unix:///var/run/docker.sock"

filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml
  reload.enabled: false

setup.template.settings:
  index.number_of_shards: 1
  index.codec: best_compression

setup.kibana:
  host: "kibana:5601"

output.logstash:
  hosts: ["logstash:5044"]

processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~

logging.level: info
logging.to_files: true
logging.files:
  path: /usr/share/filebeat/logs
  name: filebeat
  keepfiles: 7
  permissions: 0644
"""
    
    with open(config_dir / "filebeat.yml", "w", encoding="utf-8") as f:
        f.write(filebeat_yml)
    
    print(f"  âœ… Filebeaté…ç½®å·²åˆ›å»º: {config_dir / 'filebeat.yml'}")
    return True

def create_log_directories():
    """åˆ›å»ºæ—¥å¿—ç›®å½•"""
    print("ğŸ“ åˆ›å»ºæ—¥å¿—ç›®å½•...")
    
    log_dirs = [
        "logs/app",
        "logs/access", 
        "logs/security",
        "logs/system"
    ]
    
    for log_dir in log_dirs:
        Path(log_dir).mkdir(parents=True, exist_ok=True)
        print(f"  âœ… åˆ›å»ºç›®å½•: {log_dir}")
    
    return True

def deploy_elk_stack():
    """éƒ¨ç½²ELK Stack"""
    print("ğŸš€ éƒ¨ç½²ELK Stack...")
    
    try:
        # åœæ­¢ç°æœ‰æœåŠ¡
        print("  ğŸ›‘ åœæ­¢ç°æœ‰æœåŠ¡...")
        subprocess.run([
            "docker-compose", "-f", "docker-compose.elk.yml", "down"
        ], capture_output=True)
        
        # å¯åŠ¨æœåŠ¡
        print("  ğŸš€ å¯åŠ¨ELKæœåŠ¡...")
        result = subprocess.run([
            "docker-compose", "-f", "docker-compose.elk.yml", "up", "-d"
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"  âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {result.stderr}")
            return False
        
        print("  âœ… ELKæœåŠ¡å¯åŠ¨æˆåŠŸ")
        
        # ç­‰å¾…æœåŠ¡å¯åŠ¨
        print("  â³ ç­‰å¾…æœåŠ¡å¯åŠ¨...")
        time.sleep(60)  # ELKéœ€è¦æ›´é•¿æ—¶é—´å¯åŠ¨
        
        # æ£€æŸ¥æœåŠ¡çŠ¶æ€
        print("  ğŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€...")
        status_result = subprocess.run([
            "docker-compose", "-f", "docker-compose.elk.yml", "ps"
        ], capture_output=True, text=True)
        
        print("  ğŸ“Š æœåŠ¡çŠ¶æ€:")
        print(status_result.stdout)
        
        return True
        
    except Exception as e:
        print(f"  âŒ éƒ¨ç½²å¤±è´¥: {str(e)}")
        return False

async def configure_elk_stack():
    """é…ç½®ELK Stack"""
    print("âš™ï¸  é…ç½®ELK Stack...")
    
    try:
        # ç­‰å¾…ELKæœåŠ¡å®Œå…¨å¯åŠ¨
        print("  â³ ç­‰å¾…ELKæœåŠ¡å®Œå…¨å¯åŠ¨...")
        max_retries = 60
        for i in range(max_retries):
            try:
                status = await elk_service.get_elk_status()
                if (status.get("elasticsearch", {}).get("connected") and 
                    status.get("kibana", {}).get("connected")):
                    print("  âœ… ELKæœåŠ¡å·²å¯åŠ¨")
                    break
            except:
                pass
            
            if i == max_retries - 1:
                print("  âŒ ELKæœåŠ¡å¯åŠ¨è¶…æ—¶")
                return False
            
            time.sleep(10)
        
        # è®¾ç½®ELKé…ç½®
        print("  ğŸ“Š è®¾ç½®ELKé…ç½®...")
        setup_result = await setup_elk_logging()
        
        if setup_result.get("status") == "success":
            print("  âœ… ELKé…ç½®è®¾ç½®æˆåŠŸ")
            
            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            elasticsearch = setup_result.get("elasticsearch", {})
            kibana = setup_result.get("kibana", {})
            indices = setup_result.get("indices", [])
            dashboards = setup_result.get("dashboards", [])
            
            print(f"    ğŸ” Elasticsearch: {elasticsearch.get('cluster_status', 'unknown')}")
            print(f"    ğŸ“Š Kibana: {kibana.get('overall_status', 'unknown')}")
            print(f"    ğŸ“‹ ç´¢å¼•æ¨¡æ¿: {len([i for i in indices if i['status'] == 'created'])} ä¸ª")
            print(f"    ğŸ“ˆ ä»ªè¡¨ç›˜: {len([d for d in dashboards if d['status'] == 'created'])} ä¸ª")
            
            return True
        else:
            print(f"  âŒ ELKé…ç½®å¤±è´¥: {setup_result.get('errors', [])}")
            return False
            
    except Exception as e:
        print(f"  âŒ é…ç½®å¤±è´¥: {str(e)}")
        return False

def print_deployment_summary():
    """æ‰“å°éƒ¨ç½²æ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“‹ ELK Stackéƒ¨ç½²æ‘˜è¦")
    print("="*60)
    print("ğŸ‰ ELK Stackæ—¥å¿—èšåˆç³»ç»Ÿéƒ¨ç½²å®Œæˆï¼")
    print("\nğŸ“Š è®¿é—®åœ°å€:")
    print("  ğŸ” Elasticsearch: http://localhost:9200")
    print("  ğŸ“Š Kibana: http://localhost:5601")
    print("  ğŸ“„ Logstash: http://localhost:9600")
    print("\nğŸ“‹ æ—¥å¿—ç±»å‹:")
    print("  ğŸ“± åº”ç”¨æ—¥å¿—: lawsker-app-logs-*")
    print("  ğŸŒ è®¿é—®æ—¥å¿—: lawsker-access-logs-*")
    print("  ğŸ”’ å®‰å…¨æ—¥å¿—: lawsker-security-logs-*")
    print("\nğŸ“‹ åç»­æ­¥éª¤:")
    print("  1. è®¿é—®Kibanaå¹¶æ£€æŸ¥ç´¢å¼•æ¨¡å¼")
    print("  2. é…ç½®æ—¥å¿—æ”¶é›†å™¨æŒ‡å‘Logstash")
    print("  3. åˆ›å»ºè‡ªå®šä¹‰ä»ªè¡¨ç›˜å’Œå¯è§†åŒ–")
    print("  4. è®¾ç½®æ—¥å¿—å‘Šè­¦è§„åˆ™")
    print("  5. é…ç½®æ—¥å¿—ä¿ç•™ç­–ç•¥")
    print("  6. è®¾ç½®å¤‡ä»½å’Œæ¢å¤ç­–ç•¥")

async def check_deployment_status():
    """æ£€æŸ¥éƒ¨ç½²çŠ¶æ€"""
    print("ğŸ” æ£€æŸ¥ELK Stackéƒ¨ç½²çŠ¶æ€...")
    
    try:
        # æ£€æŸ¥DockeræœåŠ¡
        print("\nğŸ“Š DockeræœåŠ¡çŠ¶æ€:")
        result = subprocess.run([
            "docker-compose", "-f", "docker-compose.elk.yml", "ps"
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print(result.stdout)
        else:
            print("  âŒ æ— æ³•è·å–DockeræœåŠ¡çŠ¶æ€")
        
        # æ£€æŸ¥ELKçŠ¶æ€
        print("\nğŸ“Š ELK StackçŠ¶æ€:")
        elk_status = await elk_service.get_elk_status()
        
        for service, status in elk_status.items():
            if status.get("connected"):
                print(f"  âœ… {service.capitalize()}: è¿æ¥æ­£å¸¸")
                if service == "elasticsearch":
                    print(f"    é›†ç¾¤çŠ¶æ€: {status.get('status', 'unknown')}")
                    print(f"    èŠ‚ç‚¹æ•°é‡: {status.get('number_of_nodes', 0)}")
                elif service == "kibana":
                    print(f"    ç‰ˆæœ¬: {status.get('version', 'unknown')}")
                    print(f"    çŠ¶æ€: {status.get('status', 'unknown')}")
            else:
                print(f"  âŒ {service.capitalize()}: è¿æ¥å¤±è´¥")
                if "error" in status:
                    print(f"    é”™è¯¯: {status['error']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ çŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}")
        return False

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print("ELK Stackæ—¥å¿—èšåˆç³»ç»Ÿéƒ¨ç½²å·¥å…·")
    print("\nç”¨æ³•:")
    print("  python deploy_elk.py [é€‰é¡¹]")
    print("\né€‰é¡¹:")
    print("  --deploy, -d    å®Œæ•´éƒ¨ç½²ELK Stack")
    print("  --config, -c    ä»…åˆ›å»ºé…ç½®æ–‡ä»¶")
    print("  --status, -s    æ£€æŸ¥éƒ¨ç½²çŠ¶æ€")
    print("  --help, -h      æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")

async def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = sys.argv[1:]
    
    if not args or "--help" in args or "-h" in args:
        show_help()
        return
    
    try:
        if "--deploy" in args or "-d" in args:
            # å®Œæ•´éƒ¨ç½²
            success = True
            
            # æ£€æŸ¥å‰ç½®æ¡ä»¶
            if not check_prerequisites():
                success = False
            
            # åˆ›å»ºé…ç½®æ–‡ä»¶
            if success:
                print_section_header("åˆ›å»ºé…ç½®æ–‡ä»¶")
                success = (
                    create_elk_docker_compose() and
                    create_elasticsearch_config() and
                    create_logstash_config() and
                    create_kibana_config() and
                    create_filebeat_config() and
                    create_log_directories()
                )
            
            # éƒ¨ç½²ELK Stack
            if success:
                print_section_header("éƒ¨ç½²ELK Stack")
                success = deploy_elk_stack()
            
            # é…ç½®ELK Stack
            if success:
                print_section_header("é…ç½®ELK Stack")
                success = await configure_elk_stack()
            
            if success:
                print_deployment_summary()
                print("\nâœ… ELK Stackéƒ¨ç½²æˆåŠŸ")
            else:
                print("\nâŒ ELK Stackéƒ¨ç½²å¤±è´¥")
            
        elif "--config" in args or "-c" in args:
            # ä»…åˆ›å»ºé…ç½®æ–‡ä»¶
            print_section_header("åˆ›å»ºé…ç½®æ–‡ä»¶")
            success = (
                create_elk_docker_compose() and
                create_elasticsearch_config() and
                create_logstash_config() and
                create_kibana_config() and
                create_filebeat_config() and
                create_log_directories()
            )
            
            if success:
                print("\nâœ… é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ")
            else:
                print("\nâŒ é…ç½®æ–‡ä»¶åˆ›å»ºå¤±è´¥")
                
        elif "--status" in args or "-s" in args:
            # æ£€æŸ¥çŠ¶æ€
            success = await check_deployment_status()
            
        else:
            print("âŒ æœªçŸ¥é€‰é¡¹ï¼Œä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©")
            success = False
        
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())