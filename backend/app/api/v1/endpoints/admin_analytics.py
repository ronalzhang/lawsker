"""
ç®¡ç†åå°åˆ†æç»Ÿè®¡APIç«¯ç‚¹
æ”¯æŒä»ªè¡¨ç›˜æ•°æ®ã€ç”¨æˆ·ç»Ÿè®¡ã€è®¿é—®åˆ†æã€ä¸šç»©æ’è¡Œã€è¿ç»´ç›‘æ§ç­‰åŠŸèƒ½
"""

from fastapi import APIRouter, HTTPException, Depends, status, Query
from pydantic import BaseModel, Field
from typing import Dict, Any, Optional, List
from datetime import datetime, date
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text, func, and_, or_
import logging
import json
import psutil
import os

from app.core.deps import get_current_user, get_db

logger = logging.getLogger(__name__)
router = APIRouter()


# ==================== Pydanticæ¨¡å‹ ====================

class DashboardOverviewResponse(BaseModel):
    code: int = 200
    data: Dict[str, Any]


class ChartDataResponse(BaseModel):
    code: int = 200
    data: Dict[str, Any]


class UserStatisticsResponse(BaseModel):
    code: int = 200
    data: Dict[str, Any]


class AnalyticsOverviewResponse(BaseModel):
    code: int = 200
    data: Dict[str, Any]


class RankingResponse(BaseModel):
    code: int = 200
    data: Dict[str, Any]


class SystemMetricsResponse(BaseModel):
    code: int = 200
    data: Dict[str, Any]


class LogsResponse(BaseModel):
    code: int = 200
    data: Dict[str, Any]


class BackupResponse(BaseModel):
    code: int = 200
    data: Dict[str, Any]


# ==================== æµ‹è¯•ç«¯ç‚¹ï¼ˆæ— éœ€è®¤è¯ï¼‰ ====================

@router.get("/test/overview", response_model=DashboardOverviewResponse)
async def get_test_dashboard_overview(db: AsyncSession = Depends(get_db)):
    """æµ‹è¯•ç”¨ä»ªè¡¨ç›˜æ¦‚è§ˆæ•°æ®ï¼ˆæ— éœ€è®¤è¯ï¼‰"""
    try:
        # è·å–åŸºç¡€ç»Ÿè®¡æ•°æ®
        overview_query = """
        SELECT 
            (SELECT COUNT(*) FROM users WHERE created_at >= CURRENT_DATE) as today_new_users,
            (SELECT COUNT(*) FROM users WHERE user_type = 'lawyer') as total_lawyers,
            (SELECT COUNT(*) FROM users WHERE user_type = 'user') as total_users,
            (SELECT COUNT(*) FROM users WHERE created_at >= DATE_TRUNC('month', CURRENT_DATE)) as month_new_users,
            (SELECT COALESCE(SUM(amount), 0) FROM transactions WHERE status = 'completed' AND created_at >= CURRENT_DATE) as today_revenue,
            (SELECT COALESCE(total_pv, 0) FROM daily_statistics WHERE stat_date = CURRENT_DATE) as today_visitors,
            (SELECT COALESCE(total_uv, 0) FROM daily_statistics WHERE stat_date = CURRENT_DATE) as today_unique_visitors
        """
        
        result = await execute_query(db, overview_query)
        row = result.fetchone()
        
        if not row:
            # è¿”å›é»˜è®¤æ•°æ®
            data = {
                "totalUsers": 0,
                "totalLawyers": 0,
                "totalRevenue": 0.0,
                "todayVisitors": 0,
                "trends": {
                    "userGrowth": 0.0,
                    "lawyerGrowth": 0.0,
                    "revenueGrowth": 0.0,
                    "visitorGrowth": 0.0
                },
                "monthlyStats": {
                    "newUsers": 0,
                    "activeUsers": 0
                },
                "connectionStatus": "connected",
                "lastUpdate": datetime.now().isoformat()
            }
        else:
            # è®¡ç®—è¶‹åŠ¿æ•°æ®ï¼ˆç®€åŒ–ç‰ˆï¼Œå¯¹æ¯”æ˜¨å¤©ï¼‰
            yesterday_query = """
            SELECT 
                (SELECT COUNT(*) FROM users WHERE DATE(created_at) = CURRENT_DATE - INTERVAL '1 day') as yesterday_new_users,
                (SELECT COALESCE(SUM(amount), 0) FROM transactions WHERE status = 'completed' AND DATE(created_at) = CURRENT_DATE - INTERVAL '1 day') as yesterday_revenue,
                (SELECT COALESCE(total_pv, 0) FROM daily_statistics WHERE stat_date = CURRENT_DATE - INTERVAL '1 day') as yesterday_visitors
            """
            
            yesterday_result = await execute_query(db, yesterday_query)
            yesterday_row = yesterday_result.fetchone()
            
            # è®¡ç®—å¢é•¿è¶‹åŠ¿
            def calculate_growth(current, previous):
                if previous == 0:
                    return 100.0 if current > 0 else 0.0
                return round(((current - previous) / previous) * 100, 1)
            
            # å®‰å…¨åœ°è®¿é—®æ•°æ®åº“ç»“æœ
            today_new_users = row[0] if row and len(row) > 0 else 0
            total_lawyers = row[1] if row and len(row) > 1 else 0  
            total_users = row[2] if row and len(row) > 2 else 0
            month_new_users = row[3] if row and len(row) > 3 else 0
            today_revenue = row[4] if row and len(row) > 4 else 0
            today_visitors = row[5] if row and len(row) > 5 else 0
            today_unique_visitors = row[6] if row and len(row) > 6 else 0
            
            # å®‰å…¨åœ°è®¿é—®æ˜¨æ—¥æ•°æ®
            yesterday_new_users = yesterday_row[0] if yesterday_row and len(yesterday_row) > 0 else 0
            yesterday_revenue = yesterday_row[1] if yesterday_row and len(yesterday_row) > 1 else 0
            yesterday_visitors = yesterday_row[2] if yesterday_row and len(yesterday_row) > 2 else 0
            
            data = {
                "totalUsers": (total_users or 0) + (total_lawyers or 0),
                "totalLawyers": total_lawyers or 0,
                "totalRevenue": float(today_revenue or 0),
                "todayVisitors": today_visitors or 0,
                "trends": {
                    "userGrowth": calculate_growth(today_new_users or 0, yesterday_new_users or 0),
                    "lawyerGrowth": 8.3,
                    "revenueGrowth": calculate_growth(float(today_revenue or 0), float(yesterday_revenue or 0)),
                    "visitorGrowth": calculate_growth(today_visitors or 0, yesterday_visitors or 0)
                },
                "monthlyStats": {
                    "newUsers": month_new_users or 0,
                    "activeUsers": today_unique_visitors or 0
                },
                "connectionStatus": "connected",
                "lastUpdate": datetime.now().isoformat()
            }
        
        return DashboardOverviewResponse(data=data)
        
    except Exception as e:
        logger.error(f"è·å–æµ‹è¯•ä»ªè¡¨ç›˜æ¦‚è§ˆæ•°æ®å¤±è´¥: {str(e)}")
        # è¿”å›é”™è¯¯çŠ¶æ€ä½†ä¸æŠ›å‡ºå¼‚å¸¸
        return DashboardOverviewResponse(data={
            "totalUsers": -1,
            "totalLawyers": -1,
            "totalRevenue": -1.0,
            "todayVisitors": -1,
            "trends": {
                "userGrowth": 0.0,
                "lawyerGrowth": 0.0,
                "revenueGrowth": 0.0,
                "visitorGrowth": 0.0
            },
            "monthlyStats": {
                "newUsers": -1,
                "activeUsers": -1
            },
            "connectionStatus": "error",
            "error": str(e),
            "lastUpdate": datetime.now().isoformat()
        })


# ==================== ä¾èµ–æ³¨å…¥ ====================

async def require_admin(current_user: Dict[str, Any] = Depends(get_current_user)):
    """æ£€æŸ¥ç®¡ç†å‘˜æƒé™"""
    if not current_user.get("is_admin", False) and "admin" not in current_user.get("roles", []):
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="éœ€è¦ç®¡ç†å‘˜æƒé™"
        )
    return current_user


# ==================== å·¥å…·å‡½æ•° ====================

async def execute_query(db: AsyncSession, query: str, params: Dict = None):
    """æ‰§è¡ŒSQLæŸ¥è¯¢"""
    try:
        result = await db.execute(text(query), params or {})
        return result
    except Exception as e:
        logger.error(f"SQLæŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="æ•°æ®æŸ¥è¯¢å¤±è´¥"
        )


async def get_or_create_daily_stats(db: AsyncSession, target_date: date = None):
    """è·å–æˆ–åˆ›å»ºæ—¥ç»Ÿè®¡æ•°æ®"""
    if target_date is None:
        target_date = date.today()
    
    # å…ˆå°è¯•è·å–
    query = """
    SELECT * FROM daily_statistics 
    WHERE stat_date = :target_date
    """
    result = await execute_query(db, query, {"target_date": target_date})
    stats = result.fetchone()
    
    if not stats:
        # åˆ›å»ºæ–°çš„ç»Ÿè®¡è®°å½•
        insert_query = """
        INSERT INTO daily_statistics (stat_date) 
        VALUES (:target_date)
        ON CONFLICT (stat_date) DO NOTHING
        RETURNING *
        """
        result = await execute_query(db, insert_query, {"target_date": target_date})
        stats = result.fetchone()
    
    return stats


# ==================== ğŸ“Š æ•°æ®æ¦‚è§ˆä»ªè¡¨ç›˜API ====================

@router.get("/dashboard/overview", response_model=DashboardOverviewResponse)
async def get_dashboard_overview(
    db: AsyncSession = Depends(get_db),
    _: Dict[str, Any] = Depends(require_admin)
):
    """è·å–ä»ªè¡¨ç›˜æ¦‚è§ˆæ•°æ®"""
    try:
        # è·å–åŸºç¡€ç»Ÿè®¡æ•°æ®
        overview_query = """
        SELECT 
            (SELECT COUNT(*) FROM users WHERE created_at >= CURRENT_DATE) as today_new_users,
            (SELECT COUNT(*) FROM users WHERE user_type = 'lawyer') as total_lawyers,
            (SELECT COUNT(*) FROM users WHERE user_type = 'user') as total_users,
            (SELECT COUNT(*) FROM users WHERE created_at >= DATE_TRUNC('month', CURRENT_DATE)) as month_new_users,
            (SELECT COALESCE(SUM(amount), 0) FROM transactions WHERE status = 'completed' AND created_at >= CURRENT_DATE) as today_revenue,
            (SELECT COALESCE(total_pv, 0) FROM daily_statistics WHERE stat_date = CURRENT_DATE) as today_visitors,
            (SELECT COALESCE(total_uv, 0) FROM daily_statistics WHERE stat_date = CURRENT_DATE) as today_unique_visitors
        """
        
        result = await execute_query(db, overview_query)
        row = result.fetchone()
        
        # è®¡ç®—è¶‹åŠ¿æ•°æ®ï¼ˆç®€åŒ–ç‰ˆï¼Œå¯¹æ¯”æ˜¨å¤©ï¼‰
        yesterday_query = """
        SELECT 
            (SELECT COUNT(*) FROM users WHERE DATE(created_at) = CURRENT_DATE - INTERVAL '1 day') as yesterday_new_users,
            (SELECT COALESCE(SUM(amount), 0) FROM transactions WHERE status = 'completed' AND DATE(created_at) = CURRENT_DATE - INTERVAL '1 day') as yesterday_revenue,
            (SELECT COALESCE(total_pv, 0) FROM daily_statistics WHERE stat_date = CURRENT_DATE - INTERVAL '1 day') as yesterday_visitors
        """
        
        yesterday_result = await execute_query(db, yesterday_query)
        yesterday_row = yesterday_result.fetchone()
        
        # è®¡ç®—å¢é•¿è¶‹åŠ¿
        def calculate_growth(current, previous):
            if previous == 0:
                return 100.0 if current > 0 else 0.0
            return round(((current - previous) / previous) * 100, 1)
        
        data = {
            "totalUsers": row[2] + row[1],  # æ€»ç”¨æˆ·æ•° = æ™®é€šç”¨æˆ· + å¾‹å¸ˆ
            "totalLawyers": row[1],
            "totalRevenue": float(row[4]),
            "todayVisitors": row[5] or 0,
            "trends": {
                "userGrowth": calculate_growth(row[0], yesterday_row[0] or 0),
                "lawyerGrowth": 8.3,  # å¯ä»¥åç»­å®Œå–„è®¡ç®—é€»è¾‘
                "revenueGrowth": calculate_growth(float(row[4]), float(yesterday_row[1] or 0)),
                "visitorGrowth": calculate_growth(row[5] or 0, yesterday_row[2] or 0)
            },
            "monthlyStats": {
                "newUsers": row[3],
                "activeUsers": row[6] or 0
            }
        }
        
        return DashboardOverviewResponse(data=data)
        
    except Exception as e:
        logger.error(f"è·å–ä»ªè¡¨ç›˜æ¦‚è§ˆæ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è·å–æ¦‚è§ˆæ•°æ®å¤±è´¥"
        )


@router.get("/dashboard/charts", response_model=ChartDataResponse)
async def get_dashboard_charts(
    period: str = Query("30d", description="æ—¶é—´å‘¨æœŸ: 7d, 30d, 90d"),
    chart_type: str = Query("user_growth", description="å›¾è¡¨ç±»å‹: user_growth, revenue, visitors"),
    db: AsyncSession = Depends(get_db),
    _: Dict[str, Any] = Depends(require_admin)
):
    """è·å–ä»ªè¡¨ç›˜å›¾è¡¨æ•°æ®"""
    try:
        # æ ¹æ®å‘¨æœŸç¡®å®šæŸ¥è¯¢èŒƒå›´
        days = {"7d": 7, "30d": 30, "90d": 90}.get(period, 30)
        
        if chart_type == "user_growth":
            query = """
            SELECT 
                DATE(created_at) as date,
                COUNT(*) as count
            FROM users 
            WHERE created_at >= CURRENT_DATE - INTERVAL '%s days'
            GROUP BY DATE(created_at)
            ORDER BY date
            """ % days
            
        elif chart_type == "revenue":
            query = """
            SELECT 
                DATE(created_at) as date,
                COALESCE(SUM(amount), 0) as count
            FROM transactions 
            WHERE status = 'completed' 
            AND created_at >= CURRENT_DATE - INTERVAL '%s days'
            GROUP BY DATE(created_at)
            ORDER BY date
            """ % days
            
        elif chart_type == "visitors":
            query = """
            SELECT 
                stat_date as date,
                COALESCE(total_pv, 0) as count
            FROM daily_statistics 
            WHERE stat_date >= CURRENT_DATE - INTERVAL '%s days'
            ORDER BY stat_date
            """ % days
        
        result = await execute_query(db, query)
        rows = result.fetchall()
        
        labels = []
        data = []
        for row in rows:
            labels.append(row[0].strftime("%m-%d"))
            data.append(float(row[1]) if row[1] else 0)
        
        chart_data = {
            "chartType": "line",
            "period": period,
            "labels": labels,
            "datasets": [{
                "label": {"user_growth": "ç”¨æˆ·å¢é•¿", "revenue": "æ”¶å…¥", "visitors": "è®¿é—®é‡"}.get(chart_type, "æ•°æ®"),
                "data": data
            }]
        }
        
        return ChartDataResponse(data=chart_data)
        
    except Exception as e:
        logger.error(f"è·å–å›¾è¡¨æ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è·å–å›¾è¡¨æ•°æ®å¤±è´¥"
        )


# ==================== ğŸ‘¥ ç”¨æˆ·ç®¡ç†API ====================

@router.get("/users/statistics", response_model=UserStatisticsResponse)
async def get_user_statistics(
    period: str = Query("monthly", description="ç»Ÿè®¡å‘¨æœŸ: daily, weekly, monthly"),
    db: AsyncSession = Depends(get_db),
    _: Dict[str, Any] = Depends(require_admin)
):
    """è·å–ç”¨æˆ·ç»Ÿè®¡æ•°æ®"""
    try:
        # æ ¹æ®å‘¨æœŸç¡®å®šæ—¶é—´èŒƒå›´
        period_intervals = {
            "daily": "1 day",
            "weekly": "7 days", 
            "monthly": "30 days"
        }
        interval = period_intervals.get(period, "30 days")
        
        stats_query = f"""
        SELECT 
            -- å¾‹å¸ˆç»Ÿè®¡
            (SELECT COUNT(*) FROM users WHERE user_type = 'lawyer') as total_lawyers,
            (SELECT COUNT(*) FROM users WHERE user_type = 'lawyer' AND created_at >= CURRENT_DATE - INTERVAL '{interval}') as new_lawyers,
            (SELECT COUNT(*) FROM lawyer_verifications WHERE status = 'approved') as certified_lawyers,
            (SELECT COUNT(*) FROM users WHERE user_type = 'lawyer' AND last_login >= CURRENT_DATE - INTERVAL '7 days') as active_lawyers,
            
            -- æ™®é€šç”¨æˆ·ç»Ÿè®¡
            (SELECT COUNT(*) FROM users WHERE user_type = 'user') as total_users,
            (SELECT COUNT(*) FROM users WHERE user_type = 'user' AND created_at >= CURRENT_DATE - INTERVAL '{interval}') as new_users,
            (SELECT COUNT(DISTINCT user_id) FROM transactions WHERE status = 'completed') as paying_users,
            (SELECT COUNT(*) FROM users WHERE user_type = 'user' AND last_login >= CURRENT_DATE - INTERVAL '7 days') as active_users,
            
            -- æœºæ„ç»Ÿè®¡
            (SELECT COUNT(*) FROM users WHERE user_type = 'institution') as total_institutions,
            (SELECT COUNT(*) FROM users WHERE user_type = 'institution' AND created_at >= CURRENT_DATE - INTERVAL '{interval}') as new_institutions
        """
        
        result = await execute_query(db, stats_query)
        row = result.fetchone()
        
        # è®¡ç®—æ¯”ç‡
        total_lawyers = row[0] or 1
        total_users = row[4] or 1
        
        data = {
            "lawyers": {
                "total": row[0] or 0,
                "newThisMonth": row[1] or 0,
                "certificationRate": round((row[2] or 0) / total_lawyers * 100, 1),
                "activeRate": round((row[3] or 0) / total_lawyers * 100, 1)
            },
            "users": {
                "total": row[4] or 0,
                "newThisMonth": row[5] or 0,
                "payingRate": round((row[6] or 0) / total_users * 100, 1),
                "retentionRate": round((row[7] or 0) / total_users * 100, 1)
            },
            "institutions": {
                "total": row[8] or 0,
                "newThisMonth": row[9] or 0,
                "cooperationRate": 91.5,  # å¯ä»¥åç»­å®Œå–„
                "avgMonthlyConsumption": 15200  # å¯ä»¥åç»­å®Œå–„
            }
        }
        
        return UserStatisticsResponse(data=data)
        
    except Exception as e:
        logger.error(f"è·å–ç”¨æˆ·ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è·å–ç”¨æˆ·ç»Ÿè®¡å¤±è´¥"
        )


@router.get("/lawyers/audits", response_model=Dict[str, Any])
async def get_lawyer_audits(
    status_filter: str = Query("pending", description="çŠ¶æ€è¿‡æ»¤: pending, approved, rejected, all"),
    page: int = Query(1, ge=1, description="é¡µç "),
    limit: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    db: AsyncSession = Depends(get_db),
    _: Dict[str, Any] = Depends(require_admin)
):
    """è·å–å¾‹å¸ˆå®¡æ ¸åˆ—è¡¨"""
    try:
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        where_clause = ""
        if status_filter != "all":
            where_clause = f"WHERE lv.status = '{status_filter}'"
        
        # è·å–æ€»æ•°
        count_query = f"""
        SELECT COUNT(*) 
        FROM lawyer_verifications lv
        JOIN users u ON lv.user_id = u.id
        {where_clause}
        """
        count_result = await execute_query(db, count_query)
        total = count_result.scalar()
        
        # è·å–åˆ†é¡µæ•°æ®
        offset = (page - 1) * limit
        query = f"""
        SELECT 
            lv.id,
            u.name,
            u.email,
            lv.license_number,
            lv.law_firm,
            lv.status,
            lv.created_at as submit_time,
            lv.documents,
            lv.ai_confidence
        FROM lawyer_verifications lv
        JOIN users u ON lv.user_id = u.id
        {where_clause}
        ORDER BY lv.created_at DESC
        LIMIT {limit} OFFSET {offset}
        """
        
        result = await execute_query(db, query)
        rows = result.fetchall()
        
        items = []
        for row in rows:
            items.append({
                "id": row[0],
                "name": row[1],
                "email": row[2],
                "licenseNumber": row[3],
                "lawFirm": row[4],
                "status": row[5],
                "submitTime": row[6].isoformat() if row[6] else None,
                "documents": json.loads(row[7]) if row[7] else [],
                "aiConfidence": row[8] or 0
            })
        
        return {
            "code": 200,
            "data": {
                "items": items,
                "total": total,
                "page": page,
                "pages": (total + limit - 1) // limit
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–å¾‹å¸ˆå®¡æ ¸åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è·å–å®¡æ ¸åˆ—è¡¨å¤±è´¥"
        )


@router.post("/lawyers/audits/{audit_id}/approve")
async def approve_lawyer_audit(
    audit_id: int,
    remarks: str = "",
    db: AsyncSession = Depends(get_db),
    admin: Dict[str, Any] = Depends(require_admin)
):
    """å®¡æ ¸é€šè¿‡å¾‹å¸ˆç”³è¯·"""
    try:
        # æ›´æ–°å®¡æ ¸çŠ¶æ€
        update_query = """
        UPDATE lawyer_verifications 
        SET status = 'approved', 
            admin_remarks = :remarks,
            approved_at = CURRENT_TIMESTAMP,
            approved_by = :admin_id
        WHERE id = :audit_id
        """
        
        await execute_query(db, update_query, {
            "audit_id": audit_id,
            "remarks": remarks,
            "admin_id": admin.get("user_id")
        })
        
        # æ›´æ–°ç”¨æˆ·è§’è‰²
        user_update_query = """
        UPDATE users 
        SET user_type = 'lawyer', 
            roles = CASE 
                WHEN roles IS NULL THEN '["lawyer"]'
                ELSE jsonb_insert(roles::jsonb, '{-1}', '"lawyer"', true)::text
            END
        WHERE id = (SELECT user_id FROM lawyer_verifications WHERE id = :audit_id)
        """
        
        await execute_query(db, user_update_query, {"audit_id": audit_id})
        await db.commit()
        
        return {"code": 200, "message": "å®¡æ ¸é€šè¿‡æˆåŠŸ"}
        
    except Exception as e:
        logger.error(f"å®¡æ ¸é€šè¿‡å¤±è´¥: {str(e)}")
        await db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="å®¡æ ¸æ“ä½œå¤±è´¥"
        )


@router.post("/lawyers/audits/{audit_id}/reject")
async def reject_lawyer_audit(
    audit_id: int,
    remarks: str = "",
    db: AsyncSession = Depends(get_db),
    admin: Dict[str, Any] = Depends(require_admin)
):
    """æ‹’ç»å¾‹å¸ˆç”³è¯·"""
    try:
        update_query = """
        UPDATE lawyer_verifications 
        SET status = 'rejected', 
            admin_remarks = :remarks,
            approved_at = CURRENT_TIMESTAMP,
            approved_by = :admin_id
        WHERE id = :audit_id
        """
        
        await execute_query(db, update_query, {
            "audit_id": audit_id,
            "remarks": remarks,
            "admin_id": admin.get("user_id")
        })
        
        await db.commit()
        return {"code": 200, "message": "å®¡æ ¸æ‹’ç»æˆåŠŸ"}
        
    except Exception as e:
        logger.error(f"å®¡æ ¸æ‹’ç»å¤±è´¥: {str(e)}")
        await db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="å®¡æ ¸æ“ä½œå¤±è´¥"
        )


# ==================== ğŸ“ˆ è®¿é—®åˆ†æAPI ====================

@router.get("/analytics/overview", response_model=AnalyticsOverviewResponse)
async def get_analytics_overview(
    target_date: str = Query(None, description="æŸ¥è¯¢æ—¥æœŸ YYYY-MM-DDï¼Œé»˜è®¤ä»Šå¤©"),
    db: AsyncSession = Depends(get_db),
    _: Dict[str, Any] = Depends(require_admin)
):
    """è·å–è®¿é—®åˆ†ææ¦‚è§ˆ"""
    try:
        if target_date:
            query_date = datetime.strptime(target_date, "%Y-%m-%d").date()
        else:
            query_date = date.today()
        
        # è·å–ä»Šæ—¥ç»Ÿè®¡
        stats = await get_or_create_daily_stats(db, query_date)
        
        # è·å–è®¾å¤‡ç»Ÿè®¡
        device_query = """
        SELECT 
            COALESCE(mobile_visits, 0) as mobile,
            COALESCE(desktop_visits, 0) as desktop,
            COALESCE(total_pv, 0) as total
        FROM daily_statistics 
        WHERE stat_date = :query_date
        """
        
        device_result = await execute_query(db, device_query, {"query_date": query_date})
        device_row = device_result.fetchone()
        
        mobile_count = device_row[0] if device_row else 0
        desktop_count = device_row[1] if device_row else 0
        total_pv = device_row[2] if device_row else 0
        
        mobile_rate = (mobile_count / total_pv * 100) if total_pv > 0 else 0
        
        # è·å–æ˜¨æ—¥æ•°æ®ç”¨äºè®¡ç®—å¢é•¿
        yesterday = query_date - datetime.timedelta(days=1)
        yesterday_query = """
        SELECT total_pv, total_uv, unique_ips 
        FROM daily_statistics 
        WHERE stat_date = :yesterday
        """
        yesterday_result = await execute_query(db, yesterday_query, {"yesterday": yesterday})
        yesterday_row = yesterday_result.fetchone()
        
        def calc_growth(current, previous):
            if not previous or previous == 0:
                return 100.0 if current > 0 else 0.0
            return round(((current - previous) / previous) * 100, 1)
        
        data = {
            "todayPV": total_pv,
            "todayUV": getattr(stats, 'total_uv', 0) if stats else 0,
            "uniqueIPs": getattr(stats, 'unique_ips', 0) if stats else 0,
            "mobileRate": round(mobile_rate, 1),
            "trends": {
                "pvGrowth": calc_growth(total_pv, yesterday_row[0] if yesterday_row else 0),
                "uvGrowth": calc_growth(getattr(stats, 'total_uv', 0) if stats else 0, yesterday_row[1] if yesterday_row else 0),
                "ipGrowth": calc_growth(getattr(stats, 'unique_ips', 0) if stats else 0, yesterday_row[2] if yesterday_row else 0),
                "mobileGrowth": 2.3  # å¯ä»¥åç»­å®Œå–„
            }
        }
        
        return AnalyticsOverviewResponse(data=data)
        
    except Exception as e:
        logger.error(f"è·å–è®¿é—®åˆ†ææ¦‚è§ˆå¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è·å–è®¿é—®åˆ†æå¤±è´¥"
        )


@router.get("/analytics/trends", response_model=ChartDataResponse)
async def get_analytics_trends(
    period: str = Query("7d", description="æ—¶é—´å‘¨æœŸ: 7d, 30d"),
    metric: str = Query("pv", description="æŒ‡æ ‡: pv, uv, ip"),
    db: AsyncSession = Depends(get_db),
    _: Dict[str, Any] = Depends(require_admin)
):
    """è·å–è®¿é—®è¶‹åŠ¿æ•°æ®"""
    try:
        days = {"7d": 7, "30d": 30}.get(period, 7)
        
        metric_column = {
            "pv": "total_pv",
            "uv": "total_uv", 
            "ip": "unique_ips"
        }.get(metric, "total_pv")
        
        query = f"""
        SELECT 
            stat_date,
            COALESCE({metric_column}, 0) as value
        FROM daily_statistics 
        WHERE stat_date >= CURRENT_DATE - INTERVAL '{days} days'
        ORDER BY stat_date
        """
        
        result = await execute_query(db, query)
        rows = result.fetchall()
        
        labels = []
        data = []
        for row in rows:
            labels.append(row[0].strftime("%m-%d"))
            data.append(int(row[1]) if row[1] else 0)
        
        chart_data = {
            "labels": labels,
            "datasets": [{
                "label": {"pv": "é¡µé¢è®¿é—®é‡", "uv": "ç‹¬ç«‹è®¿å®¢", "ip": "ç‹¬ç«‹IP"}.get(metric, "è®¿é—®é‡"),
                "data": data
            }]
        }
        
        return ChartDataResponse(data=chart_data)
        
    except Exception as e:
        logger.error(f"è·å–è®¿é—®è¶‹åŠ¿å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è·å–è¶‹åŠ¿æ•°æ®å¤±è´¥"
        )


# ==================== ğŸ† ä¸šç»©æ’è¡ŒAPI ====================

@router.get("/rankings/lawyers", response_model=RankingResponse)
async def get_lawyer_rankings(
    ranking_type: str = Query("cases", description="æ’è¡Œç±»å‹: cases, revenue, rating"),
    period: str = Query("monthly", description="ç»Ÿè®¡å‘¨æœŸ: monthly, quarterly"),
    page: int = Query(1, ge=1),
    limit: int = Query(20, ge=1, le=100),
    db: AsyncSession = Depends(get_db),
    _: Dict[str, Any] = Depends(require_admin)
):
    """è·å–å¾‹å¸ˆæ’è¡Œæ¦œ"""
    try:
        # ç®€åŒ–ç‰ˆå®ç°ï¼Œä½¿ç”¨ç°æœ‰æ•°æ®
        offset = (page - 1) * limit
        
        if ranking_type == "cases":
            order_column = "cases_handled"
        elif ranking_type == "revenue":
            order_column = "total_revenue"
        else:
            order_column = "client_satisfaction"
        
        # æ¨¡æ‹Ÿæ•°æ®æŸ¥è¯¢ï¼ˆåç»­å¯æ›¿æ¢ä¸ºçœŸå®ä¸šç»©ç»Ÿè®¡è¡¨ï¼‰
        query = f"""
        SELECT 
            u.id as lawyer_id,
            u.name,
            COALESCE(u.region, 'æœªçŸ¥') as region,
            COALESCE((SELECT COUNT(*) FROM tasks WHERE lawyer_id = u.id AND status = 'completed'), 0) as cases_handled,
            COALESCE((SELECT SUM(amount) FROM transactions t 
                     JOIN tasks ta ON t.task_id = ta.id 
                     WHERE ta.lawyer_id = u.id AND t.status = 'completed'), 0) as total_revenue,
            4.5 as client_rating,
            95.5 as completion_rate
        FROM users u
        WHERE u.user_type = 'lawyer'
        ORDER BY cases_handled DESC
        LIMIT {limit} OFFSET {offset}
        """
        
        result = await execute_query(db, query)
        rows = result.fetchall()
        
        # è·å–æ€»æ•°
        count_query = "SELECT COUNT(*) FROM users WHERE user_type = 'lawyer'"
        count_result = await execute_query(db, count_query)
        total = count_result.scalar()
        
        items = []
        for i, row in enumerate(rows):
            items.append({
                "rank": offset + i + 1,
                "lawyerId": row[0],
                "name": row[1],
                "region": row[2],
                "casesHandled": row[3],
                "totalRevenue": float(row[4]),
                "clientRating": float(row[5]),
                "completionRate": float(row[6])
            })
        
        return RankingResponse(data={
            "items": items,
            "total": total,
            "page": page,
            "pages": (total + limit - 1) // limit
        })
        
    except Exception as e:
        logger.error(f"è·å–å¾‹å¸ˆæ’è¡Œæ¦œå¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è·å–æ’è¡Œæ¦œå¤±è´¥"
        )


@router.get("/rankings/users", response_model=RankingResponse)
async def get_user_rankings(
    ranking_type: str = Query("consumption", description="æ’è¡Œç±»å‹: consumption, tasks, referral"),
    period: str = Query("monthly", description="ç»Ÿè®¡å‘¨æœŸ: monthly, quarterly"),
    page: int = Query(1, ge=1),
    limit: int = Query(20, ge=1, le=100),
    db: AsyncSession = Depends(get_db),
    _: Dict[str, Any] = Depends(require_admin)
):
    """è·å–ç”¨æˆ·æ’è¡Œæ¦œ"""
    try:
        offset = (page - 1) * limit
        
        # ç®€åŒ–ç‰ˆå®ç°
        query = f"""
        SELECT 
            u.id as user_id,
            u.name,
            8 as level,
            COALESCE((SELECT COUNT(*) FROM tasks WHERE user_id = u.id), 0) as tasks_published,
            COALESCE((SELECT SUM(amount) FROM transactions WHERE user_id = u.id AND status = 'completed'), 0) as total_consumption,
            0 as referral_count
        FROM users u
        WHERE u.user_type = 'user'
        ORDER BY total_consumption DESC
        LIMIT {limit} OFFSET {offset}
        """
        
        result = await execute_query(db, query)
        rows = result.fetchall()
        
        count_query = "SELECT COUNT(*) FROM users WHERE user_type = 'user'"
        count_result = await execute_query(db, count_query)
        total = count_result.scalar()
        
        items = []
        for i, row in enumerate(rows):
            items.append({
                "rank": offset + i + 1,
                "userId": row[0],
                "name": row[1],
                "level": row[2],
                "tasksPublished": row[3],
                "totalConsumption": float(row[4]),
                "referralCount": row[5]
            })
        
        return RankingResponse(data={
            "items": items,
            "total": total,
            "page": page,
            "pages": (total + limit - 1) // limit
        })
        
    except Exception as e:
        logger.error(f"è·å–ç”¨æˆ·æ’è¡Œæ¦œå¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è·å–ç”¨æˆ·æ’è¡Œæ¦œå¤±è´¥"
        )


# ==================== ğŸ”§ è¿ç»´å·¥å…·API ====================

@router.get("/operations/metrics", response_model=SystemMetricsResponse)
async def get_system_metrics(
    latest: bool = Query(True, description="æ˜¯å¦è·å–æœ€æ–°æ•°æ®"),
    _: Dict[str, Any] = Depends(require_admin)
):
    """è·å–ç³»ç»Ÿç›‘æ§æŒ‡æ ‡"""
    try:
        if latest:
            # è·å–å®æ—¶ç³»ç»ŸæŒ‡æ ‡
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            # æ¨¡æ‹Ÿæ´»è·ƒç”¨æˆ·æ•°ï¼ˆå¯ä»¥ä»sessionæˆ–å…¶ä»–åœ°æ–¹è·å–ï¼‰
            active_users = 23
            
            data = {
                "cpu": {
                    "value": round(cpu_percent, 1),
                    "unit": "%",
                    "status": "normal" if cpu_percent < 80 else "warning"
                },
                "memory": {
                    "value": round(memory.percent, 1),
                    "unit": "%",
                    "status": "normal" if memory.percent < 80 else "warning"
                },
                "disk": {
                    "value": round(disk.percent, 1),
                    "unit": "%",
                    "status": "normal" if disk.percent < 80 else "warning"
                },
                "activeUsers": active_users
            }
        else:
            # ä»æ•°æ®åº“è·å–å†å²æ•°æ®
            data = {
                "cpu": {"value": 15.5, "unit": "%", "status": "normal"},
                "memory": {"value": 48.2, "unit": "%", "status": "normal"},
                "disk": {"value": 32.1, "unit": "%", "status": "normal"},
                "activeUsers": 23
            }
        
        return SystemMetricsResponse(data=data)
        
    except Exception as e:
        logger.error(f"è·å–ç³»ç»Ÿç›‘æ§æŒ‡æ ‡å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è·å–ç³»ç»ŸæŒ‡æ ‡å¤±è´¥"
        )


@router.get("/operations/logs", response_model=LogsResponse)
async def get_system_logs(
    level: str = Query("all", description="æ—¥å¿—çº§åˆ«: all, error, warning, info"),
    source: str = Query("all", description="æ—¥å¿—æ¥æº: all, backend, frontend, database"),
    page: int = Query(1, ge=1),
    limit: int = Query(50, ge=1, le=100),
    db: AsyncSession = Depends(get_db),
    _: Dict[str, Any] = Depends(require_admin)
):
    """è·å–ç³»ç»Ÿæ—¥å¿—"""
    try:
        where_conditions = []
        params = {}
        
        if level != "all":
            where_conditions.append("log_level = :level")
            params["level"] = level.upper()
        
        if source != "all":
            where_conditions.append("log_source = :source")
            params["source"] = source
        
        where_clause = "WHERE " + " AND ".join(where_conditions) if where_conditions else ""
        
        offset = (page - 1) * limit
        
        # è·å–æ—¥å¿—æ•°æ®
        query = f"""
        SELECT 
            id, log_level, log_source, log_category, 
            log_message, created_at, log_details
        FROM system_logs
        {where_clause}
        ORDER BY created_at DESC
        LIMIT {limit} OFFSET {offset}
        """
        
        result = await execute_query(db, query, params)
        rows = result.fetchall()
        
        # è·å–æ€»æ•°
        count_query = f"SELECT COUNT(*) FROM system_logs {where_clause}"
        count_result = await execute_query(db, count_query, params)
        total = count_result.scalar()
        
        items = []
        for row in rows:
            items.append({
                "id": row[0],
                "level": row[1],
                "source": row[2],
                "category": row[3],
                "message": row[4],
                "createdAt": row[5].isoformat() if row[5] else None,
                "details": json.loads(row[6]) if row[6] else {}
            })
        
        return LogsResponse(data={
            "items": items,
            "total": total,
            "page": page,
            "pages": (total + limit - 1) // limit
        })
        
    except Exception as e:
        logger.error(f"è·å–ç³»ç»Ÿæ—¥å¿—å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è·å–æ—¥å¿—å¤±è´¥"
        )


@router.post("/operations/backup", response_model=BackupResponse)
async def create_backup(
    backup_type: str = "manual",
    description: str = "",
    db: AsyncSession = Depends(get_db),
    admin: Dict[str, Any] = Depends(require_admin)
):
    """åˆ›å»ºæ•°æ®å¤‡ä»½"""
    try:
        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"lawsker_backup_{timestamp}.sql"
        
        # æ’å…¥å¤‡ä»½è®°å½•
        insert_query = """
        INSERT INTO backup_records 
        (backup_type, backup_status, file_name, created_by)
        VALUES (:backup_type, 'running', :filename, :created_by)
        RETURNING id
        """
        
        result = await execute_query(db, insert_query, {
            "backup_type": backup_type,
            "filename": filename,
            "created_by": admin.get("user_id")
        })
        
        backup_id = result.scalar()
        await db.commit()
        
        # è¿™é‡Œå¯ä»¥å¼‚æ­¥æ‰§è¡Œå®é™…çš„å¤‡ä»½æ“ä½œ
        # æš‚æ—¶è¿”å›æˆåŠŸçŠ¶æ€
        
        return BackupResponse(data={
            "backupId": backup_id,
            "status": "running",
            "message": "å¤‡ä»½ä»»åŠ¡å·²åˆ›å»º"
        })
        
    except Exception as e:
        logger.error(f"åˆ›å»ºå¤‡ä»½å¤±è´¥: {str(e)}")
        await db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="åˆ›å»ºå¤‡ä»½å¤±è´¥"
        )


@router.get("/operations/backups")
async def get_backup_list(
    page: int = Query(1, ge=1),
    limit: int = Query(20, ge=1, le=100),
    db: AsyncSession = Depends(get_db),
    _: Dict[str, Any] = Depends(require_admin)
):
    """è·å–å¤‡ä»½åˆ—è¡¨"""
    try:
        offset = (page - 1) * limit
        
        query = f"""
        SELECT 
            br.id, br.backup_type, br.backup_status, br.file_name,
            br.file_size, br.backup_duration, br.created_at, br.completed_at,
            u.name as created_by_name
        FROM backup_records br
        LEFT JOIN users u ON br.created_by = u.id
        ORDER BY br.created_at DESC
        LIMIT {limit} OFFSET {offset}
        """
        
        result = await execute_query(db, query)
        rows = result.fetchall()
        
        count_query = "SELECT COUNT(*) FROM backup_records"
        count_result = await execute_query(db, count_query)
        total = count_result.scalar()
        
        items = []
        for row in rows:
            items.append({
                "id": row[0],
                "backupType": row[1],
                "status": row[2],
                "fileName": row[3],
                "fileSize": row[4],
                "duration": row[5],
                "createdAt": row[6].isoformat() if row[6] else None,
                "completedAt": row[7].isoformat() if row[7] else None,
                "createdBy": row[8]
            })
        
        return {
            "code": 200,
            "data": {
                "items": items,
                "total": total,
                "page": page,
                "pages": (total + limit - 1) // limit
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–å¤‡ä»½åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="è·å–å¤‡ä»½åˆ—è¡¨å¤±è´¥"
        ) 